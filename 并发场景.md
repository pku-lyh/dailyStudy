# <font style="color:#DF2A3F;">高并发场景优化手段（流量很大的时候机器承载不住流量应该怎么办）</font>
## 1、分而治之，横向扩展
如果你**只部署一个应用，只部署一台服务器**，那抗住的流量请求是非常有限的。并且，单体的应用，有单点的风险，如果它挂了，那服务就不可用了。

因此，设计一个高并发系统，我们可以**分而治之，横向扩展**。也就是说，采用分布式部署的方式，部署多台服务器，把流量分流开，让每个服务器都承担一部分的并发和流量，提升**整体系统的并发能力**。

## 2、微服务拆分（系统拆分）
要提高系统的吞吐，提高系统的处理并发请求的能力。除了采用**分布式部署的方式**外，还可以做**微服务拆分**，这样就可以达到分摊请求流量的目的，提高了并发能力。

所谓的**微服务拆分**，其实就是把一个单体的应用，按功能单一性，拆分为多个服务模块。**比如一个电商系统，拆分为用户系统、订单系统、商品系统等等**。

![](https://cdn.nlark.com/yuque/0/2025/webp/39185937/1742358914532-fc930d00-895f-4b16-bef7-f97af88013cc.webp)

## 3、 分库分表
当业务量暴增的话，MySQL单机**磁盘容量会撑爆**。并且，我们知道数据库连接数是有限的。**在高并发的场景下**，大量请求访问数据库，`MySQL`单机是扛不住的！高并发场景下，会出现`too many connections`报错。

所以高并发的系统，**需要考虑拆分为多个数据库，来抗住高并发的毒打**。而假如你的单表数据量非常大，存储和查询的性能就会遇到瓶颈了，如果你做了很多优化之后还是无法提升效率的时候，就需要考虑做**分表**了。一般千万级别数据量，就需要**分表**，每个表的数据量少一点，提升SQL查询性能。

## 4、 池化技术
在高并发的场景下，**数据库连接数**可能成为瓶颈，因为连接数是有限的。

我们的请求调用数据库时，都会先获取数据库的连接，然后依靠这个连接来查询数据，搞完收工，最后关闭连接，释放资源。如果我们不用数据库连接池的话，每次执行`SQL`，都要创建连接和销毁连接，这就会导致每个查询请求都变得更慢了，相应的，系统处理用户请求的能力就降低了。

因此，需要使用池化技术，即**数据库连接池、HTTP 连接池、Redis 连接池**等等。使用数据库连接池，可以避免每次查询都新建连接，减少不必要的资源开销，通过复用连接池，**提高系统处理高并发请求的能力**。

同理，我们使用线程池，也能**让任务并行处理，更高效地完成任务**。

## 5、 主从分离
通常来说，一台单机的MySQL服务器，可以支持`500`左右的`TPS`和`10000`左右的`QPS`，即单机支撑的**请求访问是有限**的。因此你做了分布式部署，部署了多台机器，部署了主数据库、从数据库。

但是，如果双十一搞活动，流量肯定会猛增的。如果所有的查询请求，都走主库的话，主库肯定扛不住，因为查询请求量是非常非常大的。因此一般都要求做**主从分离**，然后实时性要求不高的读请求，都去读从库，**写的请求或者实时性要求高的请求，才走主库**。这样就很好保护了主库，也提高了系统的吞吐。

当然，如果回答了主从分离，面试官可能扩展开问你**主从复制原理，问你主从延迟问题**等等

## 6、使用Redis缓存
### 6.1 Redis+Lua脚本进行削峰处理
削峰处理是用于控制流量突增的一种方法，防止系统在短时间内处理过多请求导致崩溃。Redis 是一个高性能的内存数据库，结合 Lua 脚本可以实现高效的削峰处理。

#### 1. 固定窗口算法（Fixed Window）
固定窗口算法是最简单的限流算法。它统计在固定的时间窗口内请求的数量，如果超过阈值则拒绝后续请求。

**实现思路：**

+ 使用 Redis 的 `INCR` 命令来增加计数器。
+ 使用 `EXPIRE` 命令设置计数器的过期时间。
+ 如果计数器超过阈值，拒绝请求。

#### 2. 滑动窗口算法（Sliding Window）
滑动窗口算法解决了固定窗口算法的突涌问题。它记录每个请求的时间戳，只计算在时间窗口内的请求数量。

**实现思路：**

+ 使用 Redis 的有序集合（`ZSET`）来记录请求的时间戳。
+ 定期移除超出时间窗口的请求。
+ 统计当前时间窗口内的请求数量。

#### 3. 令牌桶算法（Token Bucket）（推荐，应该是主流的限流策略）
令牌桶算法允许在短时间内突发请求，但平均速率被控制在阈值以下。

**实现思路：**

+ 令牌桶维护一个令牌数量，每秒补充固定数量的令牌。
+ 每次请求消耗一个令牌，如果令牌不足则拒绝。

#### 4. 漏桶算法（Leaky Bucket）
漏桶算法是一种控制请求流出速率的算法，通常用于防止系统过载。

**实现思路：**

+ 漏桶算法与令牌桶算法相反，允许突发请求，但控制流出速率。
+ 使用 Redis 的计数器和延迟队列来实现。

#### 总结
以上是几种常见的限流算法的 Redis + Lua 实现。每种算法都有其适用场景：

+ **固定窗口**：简单易用，但可能会导致突涌。
+ **滑动窗口**：更精确，但实现复杂度较高。
+ **令牌桶**：允许突发请求，适合处理不均匀的流量。
+ **漏桶**：控制请求流出速率，适合防止系统过载。  
在实际应用中，可以根据具体需求选择合适的算法，并根据实际情况调整参数。

### 6.2 Redis提前预热存储库存信息
#### 1. Redis预热存储库存信息更快
+ **内存存储**：Redis将数据存储在内存中，与磁盘存储的数据库相比，访问速度更快。
+ **高效的读写操作**：Redis为高并发场景设计，支持高频率的读写操作，适合库存这种需要频繁更新的场景。
+ **减少数据库压力**：预热到Redis后，大部分请求直接访问缓存，减轻了数据库的负担，提升整体响应速度。

#### 2. 保证不超卖
**原子操作**：

使用Redis的`DECR`命令，原子地减少库存。确保每次扣减都是单个操作，防止多个请求同时修改库存导致超卖。

#### 3.异步更新数据库
**目的：**

+ 在成功扣减 Redis 中库存后，将扣减数据库库存的操作异步化，避免同步写数据库带来的高延迟与数据库压力。

**实现思路：**

+ **方案 A：延迟队列 + 定时任务**
    1. 用户下单后，将扣减数据库库存的命令（或订单消息）放入延迟队列中。
    2. 定时任务定时消费延迟队列中的消息，批量更新数据库库存。
+ **方案 B：消息队列异步更新**
    1. 将扣减库存的消息发送到消息队列（例如 RabbitMQ、Kafka）。
    2. 后台消费者异步处理这些消息，更新数据库库存，这样能利用 MQ 的高吞吐和解耦特性。

## 7、消息队列，削峰
我们搞一些双十一、双十二等运营活动时，需要**避免流量暴涨，打垮应用系统的风险**。因此一般会引入消息队列，来应对**高并发的场景**。

![](https://cdn.nlark.com/yuque/0/2025/webp/39185937/1742359640539-86953855-afb4-4c3f-acae-da165bec34d6.webp)

假设你的应用系统每秒最多可以处理`2k`个请求，每秒却有`5k`的请求过来，可以引入消息队列，应用系统每秒从消息队列拉`2k`请求处理得了。

有些伙伴担心这样可能会出现**消息积压**的问题：

+ 首先，搞一些运营活动，不会每时每刻都那么多请求过来你的系统（**除非有人恶意攻击**），高峰期过去后，积压的请求可以慢慢处理；
+ 其次，如果消息队列长度超过最大数量，可以直接抛弃用户请求或跳转到错误页面；

## 8、 ElasticSearch
`Elasticsearch`，大家都使用得比较多了吧，**一般搜索功能都会用到它**。它是一个分布式、高扩展、高实时的搜索与数据分析引擎，简称为`ES`。

我们在聊高并发，为啥聊到`ES`呢？ 因为`ES`可以扩容方便，天然支撑高并发。**当数据量大的时候，不用动不动就加机器扩容，分库等等**，可以考虑用`ES`来支持简单的查询搜索、统计类的操作。

# 场景题
#### 问：多线程调用类的静态方法，对局部变量进行i++五十次的操作，最后各个线程的值是多少
答：都是50，因为线程的虚拟机栈是私有的，局部变量是存在局部变量表里面的，如果是一个静态变量的话，才会出现并发问题。

#### 问：如果有一个场景，需要你给别人发id，id不能重复，比如订单id，应该怎么设计更高效。
答：具体我也不知道面试官到底想考察什么，反正意思不借助redis和数据库，还问了我UUID的原理，感觉可能解决方案如下？

#### ✅ **方案一：UUID**
+ **UUID（Universally Unique Identifier）** 是一种**通用唯一标识符**，长度为 128 位，通常以 36 个字符的字符串表示（带 4 个 `-` 分隔符）。
+ 示例：`550e8400-e29b-41d4-a716-446655440000`

**优点：**

+ 唯一性强，几乎不会重复。
+ 不依赖数据库或第三方服务。

**缺点：**

+ **不具有趋势递增性**，在 MySQL 等数据库中作为主键时，写入性能差。
+ 占用空间大（16 字节），不适合大规模使用。

✅ **适合场景：**

+ 无需排序的唯一标识，如日志追踪、临时会话 ID 等。

#### ✅ **方案二：雪花算法（Snowflake）**
+ **雪花算法**是 Twitter 开源的分布式 ID 生成算法，生成 64 位的有序 ID：

```plain
arduino


复制编辑
| 1 bit 符号位 | 41 bit 时间戳 | 10 bit 机器 ID | 12 bit 序列号 |
```

✅ **ID 结构解析：**

+ **1 bit 符号位**：始终为 0，表示正数。
+ **41 bit 时间戳**：可以使用约 69 年。
+ **10 bit 机器 ID**：最多支持 1024 个节点。
+ **12 bit 序列号**：同一毫秒内可以生成 4096 个 ID。

✅ **示例 ID：**

```plain
复制编辑
1010100000010010111001010010000010010010001000000010
```

+ 时间戳部分保证了**趋势递增性**，便于数据库索引。
+ 每毫秒生成 4096 个 ID，**高并发场景性能极高**。

✅ **优点：**

+ 高性能，生成速度快。
+ 支持分布式生成，避免重复。
+ 时间戳保证趋势递增，插入数据库性能高。

✅ **缺点：**

+ **时间回拨问题**：服务器时间调整可能导致 ID 重复。
+ **依赖机器 ID**，需要维护机器号。

✅ **适合场景：**

+ 高并发、分布式环境，例如订单 ID、消息 ID 等。

#### 问：违禁词匹配，过滤含有违禁词的话
答：主要思路是建立一颗字典树（前缀树），将违禁词加入到树中，然后再对字符串进行比对。

AC自动机，基于字典树和Fail指针

![](https://cdn.nlark.com/yuque/0/2025/png/39185937/1742290468373-1a1a04f1-f002-44c8-810c-69b9e1639cd5.png)

<font style="color:rgb(77, 77, 77);">AC自动机在Trie树的基础上，为每个节点加入了Fail指针，上图使用虚线画出了部分节点的Fail指针，未画出虚线的节点，其Fail指针指向根节点。算法在某个节点匹配失败时，可以通过该指针转移到其他包含相同前缀的分支上继续匹配。</font>

<font style="color:rgb(77, 77, 77);">例如匹配目标串“shis”时，对于前两个字符“sh”，Trie字典树匹配到左边字数的“h”节点上，由于该节点的子节点是字符“e”，与目标串的下一个字符“i”不匹配，因此算法通过Fail指针转移到中间子树的“h”节点上继续匹配，最终命中字符串“his”。</font>

<font style="color:rgb(77, 77, 77);">上述的Trie字典树与Fail指针组成了AC自动机的数据</font><font style="color:rgb(78, 161, 219) !important;">模型</font><font style="color:rgb(77, 77, 77);">。AC自动机匹配目标串时，会按顺序从目标串中取出字符，从Trie字典树的根节点出发，在子结点中寻找与该字符匹配的结点，若能找到，则转移到该节点，若找不到，则转移到Fail指针指向的节点。当状态转移到图中的红色节点时，就是命中了一个模式串。下图展示了AC自动机对目标串“merashisnx”进行匹配的过程。</font>

![](https://cdn.nlark.com/yuque/0/2025/gif/39185937/1742290538627-e68c1042-9231-47ae-8ff4-8a9a96e5b337.gif)

Fail指针计算方法：

根节点和第一个节点的Fail节点指针都指向root节点。

使用**BFS（广度优先遍历）**来计算 Fail 指针：

1. 从**根节点的子节点**开始，依次计算其 Fail 指针。
2. 对于每个节点： 
    - 找到当前节点的父节点的 Fail 指针。
    - 在父节点的 Fail 跳转位置，沿着当前字符寻找是否存在相同字符。
    - 如果存在，则指向该位置。
    - 如果不存在，继续向上回溯，直到找到对应节点或回到根节点。
3. 终止条件： 
    - 如果父节点 Fail 跳转到根节点仍然无法匹配，则当前节点的 Fail 指针指向根节点。

