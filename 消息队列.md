# Kafka
## 和其他消息队列相比,Kafka 的优势在哪里？
我们现在经常提到 Kafka 的时候就已经默认它是一个非常优秀的消息队列了，我们也会经常拿它跟 RocketMQ、RabbitMQ 对比。我觉得 Kafka 相比其他消息队列主要的优势如下：

1. **极致的性能**：基于 Scala 和 Java 语言开发，设计中大量使用了批量处理和异步的思想，最高可以每秒处理千万级别的消息。
2. **生态系统兼容性无可匹敌**：Kafka 与周边生态系统的兼容性是最好的没有之一，尤其在大数据和流计算领域。

## <font style="color:#DF2A3F;">发布-订阅模型:Kafka 消息模型</font>
发布-订阅模型主要是为了解决队列模型存在的问题。

![](https://cdn.nlark.com/yuque/0/2025/png/39185937/1742186127898-108a7c86-fdaf-412f-b812-40fdddd8432b.png)

发布订阅模型（Pub-Sub） 使用**主题（Topic）** 作为消息通信载体，类似于**广播模式**；发布者发布一条消息，该消息通过主题传递给所有的订阅者，**在一条消息广播之后才订阅的用户则是收不到该条消息的**。

**在发布 - 订阅模型中，如果只有一个订阅者，那它和队列模型就基本是一样的了。所以说，发布 - 订阅模型在功能层面上是可以兼容队列模型的。**

### 核心概念
Kafka 将生产者发布的消息发送到 **Topic（主题）** 中，需要这些消息的消费者可以订阅这些 **Topic（主题）**，如下图所示：

![](https://cdn.nlark.com/yuque/0/2025/png/39185937/1742186386850-e59b3d80-c633-4c15-81f3-cf96a3eedf07.png)

上面这张图也为我们引出了，Kafka 比较重要的几个概念：

1. **Producer（生产者）** : 产生消息的一方。
2. **Consumer（消费者）** : 消费消息的一方。
3. **Broker（代理）** : 可以看作是一个独立的 Kafka 实例。多个 Kafka Broker 组成一个 Kafka Cluster。

同时，你一定也注意到每个 Broker 中又包含了 Topic 以及 Partition 这两个重要的概念：

+ **Topic（主题）** : Producer 将消息发送到特定的主题，Consumer 通过订阅特定的 Topic(主题) 来消费消息。
+ **Partition（分区）** : Partition 属于 Topic 的一部分。一个 Topic 可以有多个 Partition ，并且同一 Topic 下的 Partition 可以分布在不同的 Broker 上，这也就表明一个 Topic 可以横跨多个 Broker 。这正如我上面所画的图一样。

## Kafka的多副本机制
Kafka 为分区（Partition）引入了多副本（Replica）机制。分区（Partition）中的多个副本之间会有一个叫做 leader 的家伙，其他副本称为 follower。我们发送的消息会被发送到 leader 副本，然后 follower 副本才能从 leader 副本中拉取消息进行同步。

生产者和消费者只与 leader 副本交互。你可以理解为其他副本只是 leader 副本的拷贝，它们的存在只是为了保证消息存储的安全性。当 leader 副本发生故障时会从 follower 中选举出一个 leader,但是 follower 中如果有和 leader 同步程度达不到要求的参加不了 leader 的竞选。

**好处：**

1. Kafka 通过给特定 Topic 指定多个 Partition, 而各个 Partition 可以分布在不同的 Broker 上, 这样便能提供比较好的并发能力（负载均衡）。
2. Partition 可以指定对应的副本（Replica） 数, 这也极大地提高了消息存储的安全性, 提高了容灾能力，不过也相应的增加了所需要的存储空间。

## <font style="color:#DF2A3F;">Kafka 如何保证消息的消费顺序？</font>
分区内的消息消费顺序是有序的，消息在被追加到 Partition(分区)的时候都会分配一个特定的偏移量（offset）。Kafka 通过偏移量（offset）来保证消息在分区内的顺序性。

Kafka 中发送 1 条消息的时候，可以指定 topic, partition, key,data（数据） 4 个参数。如果你发送消息的时候指定了 Partition 的话，所有消息都会被发送到指定的 Partition。并且，同一个 key 的消息可以保证只发送到同一个 partition，这个我们可以采用表/对象的 id 来作为 key 。

总结一下，对于如何保证 Kafka 中消息消费的顺序，有了下面两种方法：

1. 1 个 Topic 只对应一个 Partition。
2. （推荐）发送消息的时候指定 key/Partition。

## <font style="color:#DF2A3F;">Kafka 如何保证消息不丢失？</font>
### 生产者丢失消息的情况
生产者(Producer) 调用`send`方法发送消息之后，消息可能因为网络问题并没有发送过去。

所以，我们不能默认在调用`send`方法发送消息之后消息发送成功了。为了确定消息是发送成功，我们要判断消息发送的结果。但是要注意的是 Kafka 生产者(Producer) 使用 `send` 方法发送消息实际上是异步的操作，我们可以通过 `get()`方法获取调用结果，但是这样也让它变为了同步操作。

<font style="color:rgb(60, 60, 67);">因此一般不推荐这么做！可以采用为其添加回调函数的形式</font>如果消息发送失败的话，我们检查失败的原因之后重新发送即可！

<font style="color:rgb(60, 60, 67);">另外，这里推荐为 Producer 的</font>`<font style="color:rgb(60, 60, 67);">retries</font>`<font style="color:rgb(60, 60, 67);">（重试次数）设置一个比较合理的值，一般是 3 ，但是为了保证消息不丢失的话一般会设置比较大一点。设置完成之后，当出现网络问题之后能够自动重试消息发送，避免消息丢失。另外，建议还要设置重试间隔，因为间隔太小的话重试的效果就不明显了，网络波动一次你 3 次一下子就重试完了。</font>

### 消费者丢失消息的情况
我们知道消息在被追加到 Partition(分区)的时候都会分配一个特定的偏移量（offset）。偏移量（offset)表示 Consumer 当前消费到的 Partition(分区)的所在的位置。Kafka 通过偏移量（offset）可以保证消息在分区内的顺序性。

当消费者拉取到了分区的某个消息之后，消费者会自动提交了 offset。自动提交的话会有一个问题，试想一下，当消费者刚拿到这个消息准备进行真正消费的时候，突然挂掉了，消息实际上并没有被消费，但是 offset 却被自动提交了。

**解决办法也比较粗暴，我们手动关闭自动提交 offset，每次在真正消费完消息之后再自己手动提交 offset 。** 但是，细心的朋友一定会发现，这样会带来消息被重新消费的问题。比如你刚刚消费完消息之后，还没提交 offset，结果自己挂掉了，那么这个消息理论上就会被消费两次。

### Kafka 弄丢了消息
我们知道 Kafka 为分区（Partition）引入了多副本（Replica）机制。分区（Partition）中的多个副本之间会有一个叫做 leader 的家伙，其他副本称为 follower。我们发送的消息会被发送到 leader 副本，然后 follower 副本才能从 leader 副本中拉取消息进行同步。生产者和消费者只与 leader 副本交互。你可以理解为其他副本只是 leader 副本的拷贝，它们的存在只是为了保证消息存储的安全性。

**试想一种情况：假如 leader 副本所在的 broker 突然挂掉，那么就要从 follower 副本重新选出一个 leader ，但是 leader 的数据还有一些没有被 follower 副本的同步的话，就会造成消息丢失。**

**设置 acks = all**

解决办法就是我们设置 **acks = all**。acks 是 Kafka 生产者(Producer) 很重要的一个参数。

acks 的默认值即为 1，代表我们的消息被 leader 副本接收之后就算被成功发送。当我们配置 **acks = all** 表示只有所有 ISR 列表的副本全部收到消息时，生产者才会接收到来自服务器的响应. 这种模式是最高级别的，也是最安全的，可以确保不止一个 Broker 接收到了消息. 该模式的延迟会很高.

**设置 replication.factor >= 3**

为了保证 leader 副本能有 follower 副本能同步消息，我们一般会为 topic 设置 **replication.factor >= 3**。这样就可以保证每个 分区(partition) 至少有 3 个副本。虽然造成了数据冗余，但是带来了数据的安全性。

**设置 min.insync.replicas > 1**

一般情况下我们还需要设置 **min.insync.replicas> 1** ，这样配置代表消息至少要被写入到 2 个副本才算是被成功发送。**min.insync.replicas** 的默认值为 1 ，在实际生产中应尽量避免默认值 1。

但是，为了保证整个 Kafka 服务的高可用性，你需要确保 **replication.factor > min.insync.replicas** 。为什么呢？设想一下假如两者相等的话，只要是有一个副本挂掉，整个分区就无法正常工作了。这明显违反高可用性！一般推荐设置成 **replication.factor = min.insync.replicas + 1**。

**设置 unclean.leader.election.enable = false**

**Kafka 0.11.0.0 版本开始 unclean.leader.election.enable 参数的默认值由原来的 true 改为 false**

我们最开始也说了我们发送的消息会被发送到 leader 副本，然后 follower 副本才能从 leader 副本中拉取消息进行同步。多个 follower 副本之间的消息同步情况不一样，当我们配置了 **unclean.leader.election.enable = false** 的话，当 leader 副本发生故障时就不会从 follower 副本中和 leader 同步程度达不到要求的副本中选择出 leader ，这样降低了消息丢失的可能性。

## <font style="color:#DF2A3F;">Kafka 如何保证消息不重复消费？</font>
**kafka 出现消息重复消费的原因：**

+ 服务端侧已经消费的数据没有成功提交 offset（根本原因）。
+ Kafka 侧 由于服务端处理业务时间长或者网络链接等等原因让 Kafka 认为服务假死，触发了分区 rebalance。

**解决方案：**

+ **消费消息服务做幂等校验，比如 Redis 的 set、MySQL 的主键等天然的幂等功能。这种方法最有效。**
+ 将 `**enable.auto.commit**` 参数设置为 false，关闭自动提交，开发者在代码中手动提交 offset。那么这里会有个问题：**什么时候提交 offset 合适？**
    - 处理完消息再提交：依旧有消息重复消费的风险，和自动提交一样
    - 拉取到消息即提交：会有消息丢失的风险。允许消息延时的场景，一般会采用这种方式。然后，通过定时任务在业务不繁忙（比如凌晨）的时候做数据兜底。

# RabbitMQ
## 特点
+ **可靠性**: RabbitMQ 使用一些机制来保证可靠性， 如持久化、传输确认及发布确认等。
+ **灵活的路由** : 在消息进入队列之前，通过交换器来路由消息。对于典型的路由功能， RabbitMQ 己经提供了一些内置的交换器来实现。针对更复杂的路由功能，可以将多个交换器绑定在一起， 也可以通过插件机制来实现自己的交换器。
+ **扩展性**: 多个 RabbitMQ 节点可以组成一个集群，也可以根据实际业务情况动态地扩展 集群中节点。
+ **高可用性** : 队列可以在集群中的机器上设置镜像，使得在部分节点出现问题的情况下队列仍然可用。
+ **多种协议**: RabbitMQ 除了原生支持 AMQP 协议，还支持 STOMP， MQTT 等多种消息 中间件协议。
+ **多语言客户端** :RabbitMQ 几乎支持所有常用语言，比如 Java、 Python、 Ruby、 PHP、 C#、 JavaScript 等。
+ **管理界面** : RabbitMQ 提供了一个易用的用户界面，使得用户可以监控和管理消息、集 群中的节点等。
+ **插件机制** : RabbitMQ 提供了许多插件 ， 以实现从多方面进行扩展，当然也可以编写自 己的插件。

## 核心概念（生产者与消费者模型）
RabbitMQ 整体上是一个生产者与消费者模型，主要负责接收、存储和转发消息。可以把消息传递的过程想象成：当你将一个包裹送到邮局，邮局会暂存并最终将邮件通过邮递员送到收件人的手上，RabbitMQ 就好比由邮局、邮箱和邮递员组成的一个系统。从计算机术语层面来说，RabbitMQ 模型更像是一种交换机模型。

RabbitMQ 的整体模型架构如下：

![](https://cdn.nlark.com/yuque/0/2025/jpeg/39185937/1742201438575-221046c6-02dd-438e-903b-fab2167abfa7.jpeg)

下面我会一一介绍上图中的一些概念。

### Producer(生产者) 和 Consumer(消费者)
+ **Producer(生产者)** :生产消息的一方（邮件投递者）
+ **Consumer(消费者)** :消费消息的一方（邮件收件人）

消息一般由 2 部分组成：**消息头**（或者说是标签 Label）和 **消息体**。消息体也可以称为 payLoad ,消息体是不透明的，而消息头则由一系列的可选属性组成，这些属性包括 routing-key（路由键）、priority（相对于其他消息的优先权）、delivery-mode（指出该消息可能需要持久性存储）等。生产者把消息交由 RabbitMQ 后，RabbitMQ 会根据消息头把消息发送给感兴趣的 Consumer(消费者)。

### Exchange(交换器)
在 RabbitMQ 中，消息并不是直接被投递到 **Queue(消息队列)** 中的，中间还必须经过 **Exchange(交换器)** 这一层，**Exchange(交换器)** 会把我们的消息分配到对应的 **Queue(消息队列)** 中。

**Exchange(交换器)** 用来接收生产者发送的消息并将这些消息路由给服务器中的队列中，如果路由不到，或许会返回给 **Producer(生产者)** ，或许会被直接丢弃掉 。这里可以将 RabbitMQ 中的交换器看作一个简单的实体。

**RabbitMQ 的 Exchange(交换器) 有 4 种类型，不同的类型对应着不同的路由策略**：**direct(默认)**，**fanout**, **topic**, 和 **headers**，不同类型的 Exchange 转发消息的策略有所区别。这个会在介绍 **Exchange Types(交换器类型)** 的时候介绍到。

Exchange(交换器) 示意图如下：

![](https://cdn.nlark.com/yuque/0/2025/jpeg/39185937/1742201611682-30bcbb40-42bf-49cc-8dc2-f5633287d8bc.jpeg)

生产者将消息发给交换器的时候，一般会指定一个 **RoutingKey(路由键)**，用来指定这个消息的路由规则，而这个 **RoutingKey 需要与交换器类型和绑定键(BindingKey)联合使用才能最终生效**。

RabbitMQ 中通过 **Binding(绑定)** 将 **Exchange(交换器)** 与 **Queue(消息队列)** 关联起来，在绑定的时候一般会指定一个 **BindingKey(绑定建)** ,这样 RabbitMQ 就知道如何正确将消息路由到队列了,如下图所示。一个绑定就是基于路由键将交换器和消息队列连接起来的路由规则，所以可以将交换器理解成一个由绑定构成的路由表。Exchange 和 Queue 的绑定可以是多对多的关系。

Binding(绑定) 示意图：

![](https://cdn.nlark.com/yuque/0/2025/jpeg/39185937/1742201657247-afbd9404-d4e0-4b4c-8fc9-4d7a2d0e8f20.jpeg)

生产者将消息发送给交换器时，需要一个 RoutingKey,当 BindingKey 和 RoutingKey 相匹配时，消息会被路由到对应的队列中。在绑定多个队列到同一个交换器的时候，这些绑定允许使用相同的 BindingKey。BindingKey 并不是在所有的情况下都生效，它依赖于交换器类型，比如 fanout 类型的交换器就会无视，而是将消息路由到所有绑定到该交换器的队列中。

#### Exchange Types(交换器类型)
RabbitMQ 常用的 Exchange Type 有 **fanout**、**direct**、**topic**、**headers** 这四种（AMQP 规范里还提到两种 Exchange Type，分别为 system 与 自定义，这里不予以描述）。

**1、fanout**

fanout 类型的 Exchange 路由规则非常简单，它会把所有发送到该 Exchange 的消息路由到所有与它绑定的 Queue 中，不需要做任何判断操作，所以 fanout 类型是所有的交换机类型里面速度最快的。fanout 类型常用来广播消息。

**2、direct**

direct 类型的 Exchange 路由规则也很简单，它会把消息路由到那些 Bindingkey 与 RoutingKey 完全匹配的 Queue 中。

![](https://cdn.nlark.com/yuque/0/2025/jpeg/39185937/1742201721746-4b454330-edd4-4271-9c1a-65a9de554c66.jpeg)

以上图为例，如果发送消息的时候设置路由键为“warning”,那么消息会路由到 Queue1 和 Queue2。如果在发送消息的时候设置路由键为"Info”或者"debug”，消息只会路由到 Queue2。如果以其他的路由键发送消息，则消息不会路由到这两个队列中。

direct 类型常用在处理有优先级的任务，根据任务的优先级把消息发送到对应的队列，这样可以指派更多的资源去处理高优先级的队列。

**3、topic**

前面讲到 direct 类型的交换器路由规则是完全匹配 BindingKey 和 RoutingKey ，但是这种严格的匹配方式在很多情况下不能满足实际业务的需求。topic 类型的交换器在匹配规则上进行了扩展，它与 direct 类型的交换器相似，也是将消息路由到 BindingKey 和 RoutingKey 相匹配的队列中，但这里的匹配规则有些不同，它约定：

+ RoutingKey 为一个点号“．”分隔的字符串（被点号“．”分隔开的每一段独立的字符串称为一个单词），如 “com.rabbitmq.client”、“java.util.concurrent”、“com.hidden.client”;
+ BindingKey 和 RoutingKey 一样也是点号“．”分隔的字符串；
+ BindingKey 中可以存在两种特殊字符串“*”和“#”，用于做模糊匹配，其中“*”用于匹配一个单词，“#”用于匹配多个单词(可以是零个)。

![](https://cdn.nlark.com/yuque/0/2025/jpeg/39185937/1742201738767-f347db5c-ea0f-4341-b57e-478ef9ec101a.jpeg)

以上图为例：

+ 路由键为 “com.rabbitmq.client” 的消息会同时路由到 Queue1 和 Queue2;
+ 路由键为 “com.hidden.client” 的消息只会路由到 Queue2 中；
+ 路由键为 “com.hidden.demo” 的消息只会路由到 Queue2 中；
+ 路由键为 “java.rabbitmq.demo” 的消息只会路由到 Queue1 中；
+ 路由键为 “java.util.concurrent” 的消息将会被丢弃或者返回给生产者（需要设置 mandatory 参数），因为它没有匹配任何路由键。

**4、headers(不推荐)**

headers 类型的交换器不依赖于路由键的匹配规则来路由消息，而是根据发送的消息内容中的 headers 属性进行匹配。在绑定队列和交换器时指定一组键值对，当发送消息到交换器时，RabbitMQ 会获取到该消息的 headers（也是一个键值对的形式)，对比其中的键值对是否完全匹配队列和交换器绑定时指定的键值对，如果完全匹配则消息会路由到该队列，否则不会路由到该队列。headers 类型的交换器性能会很差，而且也不实用，基本上不会看到它的存在。

### Queue(消息队列)
**Queue(消息队列)** 用来保存消息直到发送给消费者。它是消息的容器，也是消息的终点。一个消息可投入一个或多个队列。消息一直在队列里面，等待消费者连接到这个队列将其取走。

**RabbitMQ** 中消息只能存储在 **队列** 中，这一点和 **Kafka** 这种消息中间件相反。Kafka 将消息存储在 **topic（主题）** 这个逻辑层面，而相对应的队列逻辑只是 topic 实际存储文件中的位移标识。 RabbitMQ 的生产者生产消息并最终投递到队列中，消费者可以从队列中获取消息并消费。

**多个消费者可以订阅同一个队列**，这时队列中的消息会被平均分摊（Round-Robin，即轮询）给多个消费者进行处理，而不是每个消费者都收到所有的消息并处理，这样避免消息被重复消费。

**RabbitMQ** 不支持队列层面的广播消费,如果有广播消费的需求，需要在其上进行二次开发,这样会很麻烦，不建议这样做。

### Broker（消息中间件的服务节点）
对于 RabbitMQ 来说，一个 RabbitMQ Broker 可以简单地看作一个 RabbitMQ 服务节点，或者 RabbitMQ 服务实例。大多数情况下也可以将一个 RabbitMQ Broker 看作一台 RabbitMQ 服务器。

下图展示了生产者将消息存入 RabbitMQ Broker,以及消费者从 Broker 中消费数据的整个流程。

![](https://cdn.nlark.com/yuque/0/2025/jpeg/39185937/1742201795771-000ed67e-ed8d-4082-b20d-f8bdd6c8a7ba.jpeg)

## 什么是死信队列？如何导致的？
DLX，全称为 `Dead-Letter-Exchange`，死信交换器，死信邮箱。当消息在一个队列中变成死信 (`dead message`) 之后，它能被重新发送到另一个交换器中，这个交换器就是 DLX，绑定 DLX 的队列就称之为死信队列。

**导致的死信的几种原因**：

+ 消息被拒（`Basic.Reject /Basic.Nack`) 且 `requeue = false`。
+ 消息 TTL 过期。
+ 队列满了，无法再添加。

## 什么是延迟队列？RabbitMQ 怎么实现延迟队列？
延迟队列指的是存储对应的延迟消息，消息被发送以后，并不想让消费者立刻拿到消息，而是等待特定时间后，消费者才能拿到这个消息进行消费。

RabbitMQ 本身是没有延迟队列的，要实现延迟消息，一般有两种方式：

1. 通过 RabbitMQ 本身队列的特性来实现，需要使用 RabbitMQ 的死信交换机（Exchange）和消息的存活时间 TTL（Time To Live）。
2. 在 RabbitMQ 3.5.7 及以上的版本提供了一个插件（rabbitmq-delayed-message-exchange）来实现延迟队列功能。同时，插件依赖 Erlang/OPT 18.0 及以上。

也就是说，AMQP 协议以及 RabbitMQ 本身没有直接支持延迟队列的功能，但是可以通过 TTL 和 DLX 模拟出延迟队列的功能。

## 什么是优先级队列？
RabbitMQ 自 V3.5.0 有优先级队列实现，优先级高的队列会先被消费。

可以通过`x-max-priority`参数来实现优先级队列。不过，当消费速度大于生产速度且 Broker 没有堆积的情况下，优先级显得没有意义。

## RabbitMQ 有哪些工作模式？
+ 简单模式
+ work 工作模式
+ pub/sub 发布订阅模式
+ Routing 路由模式
+ Topic 主题模式

## RabbitMQ 消息怎么传输？
由于 TCP 链接的创建和销毁开销较大，且并发数受系统资源限制，会造成性能瓶颈，所以 RabbitMQ 使用信道的方式来传输数据。信道（Channel）是生产者、消费者与 RabbitMQ 通信的渠道，信道是建立在 TCP 链接上的虚拟链接，且每条 TCP 链接上的信道数量没有限制。就是说 RabbitMQ 在一条 TCP 链接上建立成百上千个信道来达到多个线程处理，这个 TCP 被多个线程共享，每个信道在 RabbitMQ 都有唯一的 ID，保证了信道私有性，每个信道对应一个线程使用。

## 如何保证消息的可靠性？
消息到 MQ 的过程中搞丢，MQ 自己搞丢，MQ 到消费过程中搞丢。

+ 生产者到 RabbitMQ：事务机制和 Confirm 机制，注意：事务机制和 Confirm 机制是互斥的，两者不能共存，会导致 RabbitMQ 报错。
+ RabbitMQ 自身：持久化、集群、普通模式、镜像模式。
+ RabbitMQ 到消费者：basicAck 机制、死信队列、消息补偿机制。

## 如何保证 RabbitMQ 高可用的？
RabbitMQ 是比较有代表性的，因为是基于主从（非分布式）做高可用性的，我们就以 RabbitMQ 为例子讲解第一种 MQ 的高可用性怎么实现。RabbitMQ 有三种模式：单机模式、普通集群模式、镜像集群模式。

**单机模式**

Demo 级别的，一般就是你本地启动了玩玩儿的?，没人生产用单机模式。

**普通集群模式**

意思就是在多台机器上启动多个 RabbitMQ 实例，每个机器启动一个。你创建的 queue，只会放在一个 RabbitMQ 实例上，但是每个实例都同步 queue 的元数据（元数据可以认为是 queue 的一些配置信息，通过元数据，可以找到 queue 所在实例）。

你消费的时候，实际上如果连接到了另外一个实例，那么那个实例会从 queue 所在实例上拉取数据过来。这方案主要是提高吞吐量的，就是说让集群中多个节点来服务某个 queue 的读写操作。

**镜像集群模式**

这种模式，才是所谓的 RabbitMQ 的高可用模式。跟普通集群模式不一样的是，在镜像集群模式下，你创建的 queue，无论元数据还是 queue 里的消息都会存在于多个实例上，就是说，每个 RabbitMQ 节点都有这个 queue 的一个完整镜像，包含 queue 的全部数据的意思。然后每次你写消息到 queue 的时候，都会自动把消息同步到多个实例的 queue 上。RabbitMQ 有很好的管理控制台，就是在后台新增一个策略，这个策略是镜像集群模式的策略，指定的时候是可以要求数据同步到所有节点的，也可以要求同步到指定数量的节点，再次创建 queue 的时候，应用这个策略，就会自动将数据同步到其他的节点上去了。

这样的好处在于，你任何一个机器宕机了，没事儿，其它机器（节点）还包含了这个 queue 的完整数据，别的 consumer 都可以到其它节点上去消费数据。坏处在于，第一，这个性能开销也太大了吧，消息需要同步到所有机器上，导致网络带宽压力和消耗很重！RabbitMQ 一个 queue 的数据都是放在一个节点里的，镜像集群下，也是每个节点都放这个 queue 的完整数据。

## 如何解决消息队列的延时以及过期失效问题？
| 问题 | 方案 | 适用场景 |
| --- | --- | --- |
| **消费延迟（积压）** | **增加消费者并行消费** | 处理能力不足 |
| | **优化 prefetch（Qos 限制未确认消息）** | 避免一次拉取过多消息 |
| | **批量 ACK 消息** | 减少 `ACK`开销 |
| | **RabbitMQ 持久化 + 集群优化** | MQ 负载高 |
| **消息过期（TTL 失效）** | **队列级 TTL 或 消息级 TTL** | 超时自动丢弃 |
| | **使用死信队列（DLX）** | 过期后需重新处理 |
| | **使用 RabbitMQ 延迟队列插件** | 需要定时处理消息 |


✅ **推荐方案**：

+ 如果**消费速度不够快** → **增加消费者 + 预取优化**
+ 如果**消息过期丢失** → **使用死信队列（DLX）**
+ 如果**消息需要延迟消费** → **RabbitMQ 延迟队列插件**

# RPC（远程过程调用）
 RPC，即**远程过程调用**（Remote Procedure Call），是一种计算机通信协议。它允许程序调用另一台计算机上的方法或服务，就像调用本地的方法一样，而不必关注底层的网络通信细节。简单来说，RPC隐藏了网络通信的复杂性，使得分布式系统的开发变得更加简单和高效。  

## <font style="color:#DF2A3F;">RPC的底层协议是什么</font>
（RPC（远程过程调用）不是协议，只是调用方式，比如gRPC才是协议）

#### 典型 RPC 框架及底层协议
| RPC 框架 | 底层协议 | 序列化方式 | 适用场景 |
| --- | --- | --- | --- |
| **gRPC** | HTTP/2（支持 TCP） | ProtoBuf | 高性能微服务 |
| **Dubbo** | TCP（Netty）/ HTTP/2 | Hessian、ProtoBuf | 企业级微服务 |
| **Thrift** | TCP / HTTP | Thrift | 高性能跨语言 RPC |
| **Spring Cloud Feign** | HTTP/1.1 / HTTP/2 | JSON | 兼容 REST API |
| **RocketMQ RPC** | MQ（异步） | JSON / Protobuf | 事务型任务 |


## <font style="color:#DF2A3F;">RPC远程过程调用的流程</font>
#### 参与对象：
1. **客户端（服务消费端）**：调用远程方法的一端。
2. **客户端 Stub（桩）**：这其实就是一代理类。代理类主要做的事情很简单，就是把你调用方法、类、方法参数等信息传递到服务端。
3. **网络传输**：网络传输就是你要把你调用的方法的信息比如说参数啊这些东西传输到服务端，然后服务端执行完之后再把返回结果通过网络传输给你传输回来。网络传输的实现方式有很多种比如最基本的 Socket 或者性能以及封装更加优秀的 Netty（推荐）。
4. **服务端 Stub（桩）**：这个桩就不是代理类了。我觉得理解为桩实际不太好，大家注意一下就好。这里的服务端 Stub 实际指的就是接收到客户端执行方法的请求后，去执行对应的方法然后返回结果给客户端的类。
5. **服务端（服务提供端）**：提供远程方法的一端。

具体原理图如下，后面我会串起来将整个 RPC 的过程给大家说一下。

![](https://cdn.nlark.com/yuque/0/2025/jpeg/39185937/1742029374740-3c25ba1b-eba9-4638-8189-46157b2c4c56.jpeg)

#### 具体流程
1. 客户端（client）以本地调用的方式调用远程服务；
2. 客户端 Stub（client stub） 接收到调用后负责将方法、参数等组装成能够进行网络传输的消息体（序列化）：`RpcRequest`；
3. 客户端 Stub（client stub） 找到远程服务的地址，并将消息发送到服务提供端；
4. 服务端 Stub（桩）收到消息将消息反序列化为 Java 对象: `RpcRequest`；
5. 服务端 Stub（桩）根据`RpcRequest`中的类、方法、方法参数等信息调用本地的方法；
6. 服务端 Stub（桩）得到方法执行结果并将组装成能够进行网络传输的消息体：`RpcResponse`（序列化）发送至消费方；
7. 客户端 Stub（client stub）接收到消息并将消息反序列化为 Java 对象:`RpcResponse` ，这样也就得到了最终结果。over!

## <font style="color:#DF2A3F;">RPC为什么如此高效</font>
#### **1. 基于高效的序列化和反序列化**
+ 在远程调用时，数据需要在网络中传输，因此需要进行序列化和反序列化。
+ **高效的序列化协议**可以大幅度提升性能： 
    - **Protobuf（Protocol Buffers）**：二进制序列化协议，体积小、解析速度快，占用带宽少。
    - **Thrift** 和 **Avro**：也使用了高效的二进制格式，序列化和反序列化速度快。
    - 相比于 JSON 和 XML 等文本格式，二进制格式数据更小，解析速度更快，占用带宽更少。

✅ **效率对比：**

+ **JSON**：可读性高，但体积大，解析慢。
+ **Protobuf**：二进制格式，体积小，解析速度快。
+ **Protobuf 的效率远高于 JSON 和 XML**。

####  **2. 使用长连接（TCP）通信**
+ RPC 通常使用**长连接**，基于 **TCP** 协议进行通信。
+ **HTTP 通信**通常是**短连接**（一次请求对应一次连接），连接需要频繁建立和关闭，增加了网络开销。
+ 而 **RPC 基于长连接**，复用连接，减少了连接的建立和释放次数，提高了通信效率。

✅ **对比：**

+ **HTTP 短连接**： 
    - 每次请求需要新建连接，握手开销大。
+ **RPC 长连接**： 
    - 保持 TCP 长连接，减少连接开销，性能更高。

#### 3.** 小巧的通信协议**
+ **RPC 框架的通信协议**通常比 HTTP 等协议更轻量级。
+ 例如： 
    - **gRPC**：使用 HTTP/2 协议，支持**多路复用**，减少了多次握手和连接开销。
    - **Dubbo**：自定义通信协议，二进制编码，协议头仅为 16 字节，传输效率高。
+ 相比于传统的 HTTP 请求，RPC 框架封装的协议通常更小、更快，减少了传输的数据量和带宽消耗。

✅ **协议对比：**

+ **HTTP 协议头**：大约几百字节。
+ **gRPC 协议头**：仅需几十字节。
+ **Dubbo 协议头**：仅占 16 字节，传输效率更高。

#### 4.** 高效的线程模型和异步处理**
+ RPC 框架通常采用**异步非阻塞的 I/O 模型**，提升性能： 
    - **gRPC**：采用异步处理，客户端发起请求后不会阻塞等待响应，能够处理更多的并发请求。
    - **Netty 框架**：底层采用 **NIO（非阻塞 IO）**，支持多线程模型，避免了阻塞问题。
+ **线程池复用**：RPC 框架通常会使用线程池复用，减少了线程频繁创建和销毁带来的开销。

✅ **对比：**

+ **同步调用**：阻塞等待响应，效率低。
+ **异步调用**：不阻塞当前线程，可以并发处理更多请求。

#### 5.** 高效的请求复用**
+ 在高并发场景下，RPC 框架通常会**合并请求**或进行**批量处理**： 
    - 将多个小请求合并为一个大请求，减少网络传输次数。
    - **减少网络 IO 开销**，提高整体性能。

