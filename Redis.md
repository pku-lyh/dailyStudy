# Redis常见面试题
### Redis 和 Memcached 有什么区别？
**共同点：**

1. 都是基于内存的数据库，一般都用来当做缓存使用。
2. 都有过期策略。
3. 两者的性能都非常高。

**区别：**

1. Redis 支持的数据类型更丰富（String、Hash、List、Set、ZSet），而 Memcached 只支持最简单的 key-value 数据类型；
2. Redis 支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用，而 Memcached 没有持久化功能，数据全部存在内存之中，Memcached 重启或者挂掉后，数据就没了；
3. Redis 原生支持集群模式，Memcached 没有原生的集群模式，需要依靠客户端来实现往集群中分片写入数据；
4. Redis 支持发布订阅模型、Lua 脚本、事务等功能，而 Memcached 不支持；

### <font style="color:#DF2A3F;">为什么用 Redis 作为 MySQL 的缓存？</font>
1. Redis是内存数据库，访问速度非常快（高性能）
2. Redis的单机QPS是MySql的十倍，可以轻松突破10w（高并发）

### <font style="color:#DF2A3F;">Redis 常用的数据类型有哪些？</font>
Redis 中比较常见的数据类型有下面这些：

+ **5 种基础数据类型**：String（字符串）、List（列表）、Set（集合）、Hash（散列）、Zset（有序集合）。
+ **4 种特殊数据类型**：HyperLogLog（基数统计）、Bitmap（位图）、Geospatial (地理位置)、Stream（流）。

**常用场景：**

1. String 类型的应用场景：缓存对象、常规计数、分布式锁、共享 session 信息等。
2. List 类型的应用场景：消息队列（但是有两个问题：1. 生产者需要自行实现全局唯一 ID；2. 不能以消费组形式消费数据）等。
3. Hash 类型：缓存对象、购物车等。
4. Set 类型：聚合计算（并集、交集、差集）场景，比如点赞、共同关注、抽奖活动等。
5. Zset 类型：排序场景，比如排行榜、电话和姓名排序等。
6. BitMap（2.2 版新增）：二值状态统计的场景，比如签到、判断用户登陆状态、连续签到用户总数等；
7. HyperLogLog（2.8 版新增）：海量数据基数统计的场景，比如百万级网页 UV 计数等；
8. GEO（3.2 版新增）：存储地理位置信息的场景，比如滴滴叫车；
9. Stream（5.0 版新增）：消息队列，相比于基于 List 类型实现的消息队列，有这两个特有的特性：自动生成全局唯一消息ID，支持以消费组形式消费数据。  
五种常见的 Redis 数据类型是怎么实现？

### <font style="color:#DF2A3F;">五种常见的Redis数据结构是怎么实现（小林coding介绍的比较清楚）</font>
#### String 类型内部实现（SDS）
+ `len`：字符串的长度也就是已经使用的字节数
+ `alloc`：总共可用的字符空间大小，alloc-len 就是 SDS 剩余的空间大小
+ `buf[]`：实际存储字符串的数组
+ `flags`：低三位保存类型标志

**SDS 相比于 C 语言中的字符串有如下提升：**

1. **可以避免缓冲区溢出**：C 语言中的字符串被修改（比如拼接）时，一旦没有分配足够长度的内存空间，就会造成缓冲区溢出。SDS 被修改时，会先根据 len 属性检查空间大小是否满足要求，如果不满足，则先扩展至所需大小再进行修改操作。
2. **获取字符串长度的复杂度较低**：C 语言中的字符串的长度通常是经过遍历计数来实现的，时间复杂度为 O(n)。SDS 的长度获取直接读取 len 属性即可，时间复杂度为 O(1)。
3. **减少内存分配次数**：为了避免修改（增加/减少）字符串时，每次都需要重新分配内存（C 语言的字符串是这样的），SDS 实现了空间预分配和惰性空间释放两种优化策略。当 SDS 需要增加字符串时，Redis 会为 SDS 分配好内存，并且根据特定的算法分配多余的内存，这样可以减少连续执行字符串增长操作所需的内存重分配次数。当 SDS 需要减少字符串时，这部分内存不会立即被回收，会被记录下来，等待后续使用（支持手动释放，有对应的 API）。
4. **二进制安全**：C 语言中的字符串以空字符 `\0` 作为字符串结束的标识，这存在一些问题，像一些二进制文件（比如图片、视频、音频）就可能包括空字符，C 字符串无法正确保存。SDS 使用 len 属性判断字符串是否结束，不存在这个问题。

#### List类型内部实现
List 类型的底层数据结构是由**双向链表或压缩列表**实现的：

+ 如果列表的元素个数小于 512 个（默认值，可由 list-max-ziplist-entries 配置），列表每个元素的值都小于 64 字节（默认值，可由 list-max-ziplist-value 配置），Redis 会使用**压缩列表**作为 List 类型的底层数据结构；
+ 如果列表的元素不满足上面的条件，Redis 会使用**双向链表**作为 List 类型的底层数据结构；

但是在 Redis 3.2 版本之后，List 数据类型底层数据结构就只由**quicklist** 实现了，替代了双向链表和压缩列表。

#### Hash类型内部实现
Hash 类型的底层数据结构是由**压缩列表或哈希表**实现的：

+ 如果哈希类型的元素个数小于 512 个（默认值，可由 hash-max-ziplist-entries 配置），列表每个元素的值都小于 64 字节（默认值，可由 hash-max-ziplist-value 配置），Redis 会使用**压缩列表**作为 Hash类型的底层数据结构；
+ 如果哈希类型元素不满足上面条件，Redis 会使用**哈希表**作为 Hash 类型的底层数据结构。

在 Redis 7.0 中，压缩列表数据结构已经废弃了，交由 **listpack** 数据结构来实现了。

#### Set类型内部实现
Set 类型的底层数据结构是由**哈希表或整数集合**实现的：

+ 如果集合中的元素都是整数且元素个数小于 512 （默认值，set-maxintset-entries配置）个，Redis 会使用**整数集合**作为 Set 类型的底层数据结构；
+ 如果集合中的元素不满足上面条件，则 Redis 使用**哈希表**作为 Set 类型的底层数据结构。

#### ZSet类型内部实现
Zset 类型的底层数据结构是由**压缩列表或跳表**实现的：

+ 如果有序集合的元素个数小于 128 个，并且每个元素的值小于 64 字节时，Redis 会使用**压缩列表**作为 Zset 类型的底层数据结构；
+ 如果有序集合的元素不满足上面的条件，Redis 会使用**跳表**作为 Zset 类型的底层数据结构；

在 Redis 7.0 中，压缩列表数据结构已经废弃了，交由 **listpack **数据结构来实现了。

### <font style="color:#DF2A3F;">Redis是单线程的吗？</font>
**Redis 单线程指的是「接收客户端请求->解析请求 ->进行数据读写等操作->发送数据给客户端」这个过程是由一个线程（主线程）来完成的。**

但是，**Redis 程序并不是单线程的**，Redis 在启动的时候，是会**启动后台线程**（BIO）的：

+ **Redis 在 2.6 版本**，会启动 2 个后台线程，分别处理关闭文件、AOF 刷盘这两个任务；
+ **Redis 在 4.0 版本之后**，新增了一个新的后台线程，用来异步释放 Redis 内存，也就是 lazyfree 线程。例如执行 unlink key / flushdb async / flushall async 等命令，会把这些删除操作交给后台线程来执行，好处是不会导致Redis主线程卡顿。

原因是关闭文件、AOF刷盘、释放内存这些任务都是很耗时的，如果放在主线程处理很容易造成主线程卡顿。

类似一个生产者、消费者模型：

![](https://cdn.nlark.com/yuque/0/2025/png/39185937/1736225829345-073b9ff0-9718-49c7-bc5a-f5ecf4165896.png)

### Redis单线程模型
![](https://cdn.nlark.com/yuque/0/2025/png/39185937/1736225996903-b3a0a6df-6197-457f-a0a8-1819ae55922f.png)

参考[小林coding-单线程模式是怎么样的](https://xiaolincoding.com/redis/base/redis_interview.html#redis-%E5%8D%95%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%BC%8F%E6%98%AF%E6%80%8E%E6%A0%B7%E7%9A%84)，写的很详细

### <font style="color:#DF2A3F;">Redis单线程为什么这么快</font>
1. Redis 的大部分操作**都在内存中完成**，并且采用了高效的数据结构
2. Redis 采用单线程模型可以**避免了多线程之间的竞争**，省去了多线程切换带来的时间和性能上的开销，而且也不会导致死锁问题。
3. Redis 采用了 **I/O 多路复用机制**处理大量的客户端 Socket 请求，在 Redis 只运行单线程的情况下，该机制允许内核中，同时存在多个监听 Socket 和已连接 Socket。内核会一直监听这些 Socket 上的连接请求或数据请求。一旦有请求到达，就会交给 Redis 线程处理，这就实现了一个 Redis 线程处理多个 IO 流的效果

### Redis 6.0 之后为什么引入了多线程？
**随着网络硬件的性能提升，Redis 的性能瓶颈有时会出现在网络 I/O 的处理上，所以为了提高网络 I/O 的并行度，Redis 6.0 对于网络 I/O 采用多线程来处理。**

## <font style="color:#DF2A3F;">Redis持久化</font>
### AOF文件持久化
**Redis 在执行完一条写操作命令后，就会把该命令以追加的方式写入到一个文件里，然后 Redis 重启时，会读取该文件记录的命令，然后逐一执行命令的方式来进行数据恢复。**

**为什么先执行命令，再把数据写入日志呢？**

**好处：**

+ 避免额外的检查开销（写操作命令语法可能有问题，会导致后续恢复数据的时候执行出错）
+ 不会阻塞当前写操作命令的执行

坏处：

+ 数据可能会丢失（写入日志之前服务器宕机了）
+ 可能阻塞其他操作，因为将命令写入到日志的这个操作也是在主进程完成的

#### AOF 写回策略有几种？
![](https://cdn.nlark.com/yuque/0/2025/png/39185937/1736227338146-6e792ef0-9715-426f-b84a-21eb26ce7d78.png)

写操作会先追加到AOF缓冲区，然后通过write()系统调用将缓冲区数据写入AOF文件，此时数据并没有写入到硬盘，而是拷贝到了内核缓冲区 page cache，等待内核将数据写入硬盘。

+ Always：每次写操作执行完都写回
+ Everysec：每秒写回一次
+ No：意味着不由 Redis 控制写回硬盘的时机，转交给操作系统控制写回的时机

#### AOF重写
AOF 重写机制是在重写时，读取当前数据库中的所有键值对，然后将每一个键值对用一条命令记录到「新的 AOF 文件」，等到全部记录完后，就将新的 AOF 文件替换掉现有的 AOF 文件。

Redis 的**重写 AOF 过程是由后台子进程 **_**bgrewriteaof**_** 来完成的**：

+ 子进程进行 AOF 重写期间，主进程可以继续处理命令请求，从而避免阻塞主进程；
+ 子进程带有主进程的数据副本，这里使用子进程而不是线程，因为如果是使用线程，多线程之间会共享内存，那么在修改共享内存数据的时候，需要通过加锁来保证数据的安全，而这样就会降低性能。而使用子进程，创建子进程时，父子进程是共享内存数据的，不过这个共享的内存只能以只读的方式，而当父子进程任意一方修改了该共享内存，就会发生**「写时复制」**，于是父子进程就有了独立的数据副本，就不用加锁来保证数据安全。

Redis 设置了一个 **AOF 重写缓冲区**，这个缓冲区在创建 bgrewriteaof 子进程之后开始使用，在重写 AOF 期间，当 Redis 执行完一个写命令之后，它会**同时将这个写命令写入到 「AOF 缓冲区」和 「AOF 重写缓冲区」**。

当子进程完成 AOF 重写工作后，会向主进程发送一条信号，信号是进程间通讯的一种方式，且是异步的。

主进程收到该信号后，会调用一个信号处理函数，该函数主要做以下工作：

+ 将 AOF 重写缓冲区中的所有内容追加到新的 AOF 的文件中，使得新旧两个 AOF 文件所保存的数据库状态一致；
+ 新的 AOF 的文件进行改名，覆盖现有的 AOF 文件。

### RDB快照持久化
Redis 提供了两个命令来生成 RDB 文件，分别是 save 和 bgsave，他们的区别就在于是否在「主线程」里执行：

+ 执行了 save 命令，就会在主线程生成 RDB 文件，由于和执行操作命令在同一个线程，所以如果写入 RDB 文件的时间太长，**会阻塞主线程**；
+ 执行了 bgsave 命令，会创建一个子进程来生成 RDB 文件，这样可以**避免主线程的阻塞**；

Redis 还可以通过配置文件的选项来实现每隔一段时间自动执行一次 bgsave 命令，默认会提供以下配置（执行的是bgsave）：

```c
save 900 1
save 300 10
save 60 10000
```

代表多少秒内对数据库至少进行了多少次修改为触发生成RDB快照

Redis 的快照是**全量快照**，所以执行快照是一个比较重的操作，如果频率太频繁，可能会对 Redis 性能产生影响，但是频率太低有可能会造成数据的丢失太多

### 混合持久化方式
混合持久化工作在 **AOF 日志重写过程**，当开启了混合持久化时，在 AOF 重写日志时，fork 出来的重写子进程会先将与主线程共享的内存数据以 RDB 方式写入到  AOF 文件，然后主线程处理的操作命令会被记录在重写缓冲区里，重写缓冲区里的增量命令会以 AOF 方式写入到 AOF 文件，写入完成后通知主进程将新的含有 RDB 格式和 AOF 格式的 AOF 文件替换旧的的 AOF 文件。

也就是说AOF 文件的**前半部分是 RDB 格式的全量数据，后半部分是 AOF 格式的增量数据**。

**混合持久化优点：**

+ 混合持久化结合了 RDB 和 AOF 持久化的优点开头为 RDB 的格式，使得 Redis 可以更快的启动，同时结合AOF 的优点，有减低了大量数据丢失的风险。

**混合持久化缺点：**

+ AOF 文件中添加了 RDB 格式的内容，使得 AOF 文件的可读性变得很差；
+ 兼容性差，如果开启混合持久化，那么此混合持久化 AOF 文件，就不能用在 Redis 4.0 之前版本了。

### 如何选择 RDB 和 AOF？
关于 RDB 和 AOF 的优缺点，官网上面也给了比较详细的说明[Redis persistence](https://redis.io/docs/manual/persistence/)，这里结合自己的理解简单总结一下。

**RDB 比 AOF 优秀的地方**：

+ RDB 文件存储的内容是经过压缩的二进制数据， 保存着某个时间点的数据集，文件很小，适合做数据的备份，灾难恢复。AOF 文件存储的是每一次写命令，类似于 MySQL 的 binlog 日志，通常会比 RDB 文件大很多。当 AOF 变得太大时，Redis 能够在后台自动重写 AOF。新的 AOF 文件和原有的 AOF 文件所保存的数据库状态一样，但体积更小。不过， Redis 7.0 版本之前，如果在重写期间有写入命令，AOF 可能会使用大量内存，重写期间到达的所有写入命令都会写入磁盘两次。
+ 使用 RDB 文件恢复数据，直接解析还原数据即可，不需要一条一条地执行命令，速度非常快。而 AOF 则需要依次执行每个写命令，速度非常慢。也就是说，与 AOF 相比，恢复大数据集的时候，RDB 速度更快。

**AOF 比 RDB 优秀的地方**：

+ RDB 的数据安全性不如 AOF，没有办法实时或者秒级持久化数据。生成 RDB 文件的过程是比较繁重的， 虽然 BGSAVE 子进程写入 RDB 文件的工作不会阻塞主线程，但会对机器的 CPU 资源和内存资源产生影响，严重的情况下甚至会直接把 Redis 服务干宕机。AOF 支持秒级数据丢失（取决 fsync 策略，如果是 everysec，最多丢失 1 秒的数据），仅仅是追加命令到 AOF 文件，操作轻量。
+ RDB 文件是以特定的二进制格式保存的，并且在 Redis 版本演进中有多个版本的 RDB，所以存在老版本的 Redis 服务不兼容新版本的 RDB 格式的问题。
+ AOF 以一种易于理解和解析的格式包含所有操作的日志。你可以轻松地导出 AOF 文件进行分析，你也可以直接操作 AOF 文件来解决一些问题。比如，如果执行`FLUSHALL`命令意外地刷新了所有内容后，只要 AOF 文件没有被重写，删除最新命令并重启即可恢复之前的状态。

**综上**：

+ Redis 保存的数据丢失一些也没什么影响的话，可以选择使用 RDB。
+ 不建议单独使用 AOF，因为时不时地创建一个 RDB 快照可以进行数据库备份、更快的重启以及解决 AOF 引擎错误。
+ 如果保存的数据要求安全性比较高的话，建议同时开启 RDB 和 AOF 持久化或者开启 RDB 和 AOF 混合持久化。

## Redis集群
### <font style="color:#DF2A3F;">主从复制（最下面有详细的）</font>
主服务器可以进行读写操作，当发生写操作时自动将写操作同步给从服务器，而从服务器一般是只读，并接受主服务器同步过来写操作命令，然后执行这条命令。

![](https://cdn.nlark.com/yuque/0/2025/png/39185937/1736228582652-db3766fa-3687-494c-99d3-c73c1e2fd3f9.png)

注意，主从服务器之间的命令复制是**异步**进行的，无法保证强一致性。

### <font style="color:#DF2A3F;">哨兵模式</font>
哨兵模式做到了可以监控主从服务器，并且提供**主从节点故障转移的功能。**

![](https://cdn.nlark.com/yuque/0/2025/png/39185937/1736228803317-45909acc-284d-45c7-b568-480c7a469bdc.png)

### <font style="color:#DF2A3F;">切片集群模式（Redis Cluster）</font>
Redis Cluster 方案采用哈希槽（Hash Slot），来处理数据和节点之间的映射关系。在 Redis Cluster 方案中，**一个切片集群共有 16384 个哈希槽**，这些哈希槽类似于数据分区，每个键值对都会根据它的 key，被映射到一个哈希槽中，具体执行过程分为两大步：

+ 根据键值对的 key，按照CRC16 算法计算一个 16 bit 的值。
+ 再用 16bit 值对 16384 取模，得到 0~16383 范围内的模数，每个模数代表一个相应编号的哈希槽。

哈希槽怎么分配到具体的Redis节点上呢：

+ **平均分配：** 在使用 cluster create 命令创建 Redis 集群时，Redis 会自动把所有哈希槽平均分布到集群节点上。比如集群中有 9 个节点，则每个节点上槽的个数为 16384/9 个。
+ **手动分配：** 可以使用 cluster meet 命令手动建立节点间的连接，组成集群，再使用 cluster addslots 命令，指定每个节点上的哈希槽个数。

![](https://cdn.nlark.com/yuque/0/2025/png/39185937/1736229802300-d383471c-1e20-4b92-90a4-8bf454486922.png)

### 脑裂问题和解决方案
#### 脑裂问题：
在 Redis 主从架构中，部署方式一般是「一主多从」，主节点提供写操作，从节点提供读操作。 如果主节点的网络突然发生了问题，它与所有的从节点都失联了，但是此时的主节点和客户端的网络是正常的，这个客户端并不知道 Redis 内部已经出现了问题，还在照样的向这个失联的主节点写数据（过程A），此时这些数据被旧主节点缓存到了缓冲区里，因为主从节点之间的网络问题，这些数据都是无法同步给从节点的。

这时，哨兵也发现主节点失联了，它就认为主节点挂了（但实际上主节点正常运行，只是网络出问题了），于是哨兵就会在「从节点」中选举出一个 leader作为主节点，这时集群就有两个主节点了 —— **脑裂出现了**。

然后，网络突然好了，哨兵因为之前已经选举出一个新主节点了，它就会把旧主节点降级为从节点（A），然后从节点（A）会向新主节点请求数据同步，**因为第一次同步是全量同步的方式，此时的从节点（A）会清空掉自己本地的数据，然后再做全量同步。所以，之前客户端在过程 A 写入的数据就会丢失了，也就是集群产生脑裂数据丢失的问题**。

总结一句话就是：由于网络问题，集群节点之间失去联系。主从数据不同步；重新平衡选举，产生两个主服务。等网络恢复，旧主节点会降级为从节点，再与新主节点进行同步复制的时候，由于会从节点会清空自己的缓冲区，所以导致之前客户端写入的数据丢失了。

#### 解决方案：
当主节点发现从节点下线或者通信超时的总数量大于阈值时，那么禁止主节点进行写数据，直接把错误返回给客户端。

在 Redis 的配置文件中有两个参数我们可以设置：

+ min-slaves-to-write x，主节点必须要有至少 x 个从节点连接，如果小于这个数，主节点会禁止写数据。
+ min-slaves-max-lag x，主从数据复制和同步的延迟不能超过 x 秒，如果超过，主节点会禁止写数据。

即使原主库是假故障，它在假故障期间也无法响应哨兵心跳，**原主库就会被限制接收客户端写请求，客户端也就不能在原主库中写入新数据了**。**等到新主库上线时，就只有新主库能接收和处理客户端请求，此时，新写的数据会被直接写到新主库中。而原主库会被哨兵降为从库，即使它的数据被清空了，也不会有新数据丢失。**

## <font style="color:#DF2A3F;">Redis过期删除与内存淘汰</font>
### 惰性删除
不主动删除过期键，每次从数据库访问 key 时，都检测 key 是否过期，如果过期则删除该 key。

惰性删除对CPU友好，对内存不友好。

### 定期删除
每隔一段时间「随机」从数据库中取出一定数量的 key 进行检查，并删除其中的过期key。

如果已过期key的占比大于某个阈值，则重复抽查。

执行的太频繁则对内存友好对CPU不友好。

 **Redis 选择「惰性删除+定期删除」这两种策略配和使用**

### <font style="color:#DF2A3F;">Redis内存淘汰机制</font>
_**1、不进行数据淘汰的策略**_

**noeviction**（Redis3.0之后，默认的内存淘汰策略） ：它表示当运行内存超过最大设置内存时，不淘汰任何数据，而是不再提供服务，直接返回错误。

_**2、进行数据淘汰的策略**_

针对「进行数据淘汰」这一类策略，又可以细分为「在设置了过期时间的数据中进行淘汰」和「在所有数据范围内进行淘汰」这两类策略。

在设置了过期时间的数据中进行淘汰：

+ **volatile-random**：随机淘汰设置了过期时间的任意键值；
+ **volatile-ttl**：优先淘汰更早过期的键值。
+ **volatile-lru**（Redis3.0 之前，默认的内存淘汰策略）：淘汰所有设置了过期时间的键值中，最久未使用的键值；
+ **volatile-lfu**（Redis 4.0 后新增的内存淘汰策略）：淘汰所有设置了过期时间的键值中，最少使用的键值；

在所有数据范围内进行淘汰：

+ **allkeys-random**：随机淘汰任意键值;
+ **allkeys-lru**：淘汰整个键值中最久未使用的键值；
+ **allkeys-lfu**（Redis 4.0 后新增的内存淘汰策略）：淘汰整个键值中最少使用的键值。

#### Redis 是如何实现 LRU 算法的（记录访问时间）？
Redis 实现的是一种近似 LRU 算法，目的是为了更好的节约内存，它的实现方式是在 Redis 的对象结构体中添加一个额外的字段，用于记录此数据的最后一次访问时间。

缺点是**无法解决缓存污染问题**，比如应用一次读取了大量的数据，而这些数据只会被读取这一次，那么这些数据会留存在 Redis 缓存中很长一段时间，造成缓存污染。

#### Redis 是如何实现 LFU 算法的（记录访问次数）？
**在 LFU 算法中**，Redis对象头的 24 bits 的 lru 字段被分成两段来存储，高 16bit 存储 ldt(Last Decrement Time)，用来记录 key 的访问时间戳；低 8bit 存储 logc(Logistic Counter)，用来记录 key 的访问频次。

## Redis缓存设计
### <font style="color:#DF2A3F;">缓存穿透</font>
#### 什么是缓存穿透？
缓存穿透说简单点就是大量请求的 key 是不合理的，**根本不存在于缓存中，也不存在于数据库中** 。这就导致这些请求直接到了数据库上，根本没有经过缓存这一层，对数据库造成了巨大的压力，可能直接就被这么多请求弄宕机了。

![](https://cdn.nlark.com/yuque/0/2025/png/39185937/1736234394127-7b85f747-7a27-4ad3-b94e-47f288d1ac08.png)

#### 解决办法：
1. 布隆过滤器判断数据库中是否含有对应的数据
2. 缓存无效key，设置较短的过期时间
3. 接口限流

### <font style="color:#DF2A3F;">缓存击穿</font>
#### 什么是缓存击穿？
缓存击穿中，请求的 key 对应的是 **热点数据** ，该数据 **存在于数据库中，但不存在于缓存中（通常是因为缓存中的那份数据已经过期）** 。这就可能会导致瞬时大量的请求直接打到了数据库上，对数据库造成了巨大的压力，可能直接就被这么多请求弄宕机了。

![](https://cdn.nlark.com/yuque/0/2025/png/39185937/1736234548026-25862bca-a403-4261-b212-ada8fea30ba3.png)

#### 解决方法：
1. 针对热点数据提前预热，设置合理的过期时间
2. 设置热点数据永不过期或过期时间比较长
3. 加锁

### <font style="color:#DF2A3F;">缓存雪崩</font>
#### 什么是缓存雪崩？
我发现缓存雪崩这名字起的有点意思，哈哈。

实际上，缓存雪崩描述的就是这样一个简单的场景：**缓存在同一时间大面积的失效，导致大量的请求都直接落到了数据库上，对数据库造成了巨大的压力。** 这就好比雪崩一样，摧枯拉朽之势，数据库的压力可想而知，可能直接就被这么多请求弄宕机了。

另外，缓存服务宕机也会导致缓存雪崩现象，导致所有的请求都落到了数据库上。

![](https://cdn.nlark.com/yuque/0/2025/png/39185937/1736234630150-883b96c9-39d1-45ce-ba89-acc2cdff2769.png)

#### 解决方法：
**针对 Redis 服务不可用的情况：**

1. **Redis 集群**：采用 Redis 集群，避免单机出现问题整个缓存服务都没办法使用。Redis Cluster 和 Redis Sentinel 是两种最常用的 Redis 集群实现方案。
2. **多级缓存**：设置多级缓存，例如本地缓存+Redis 缓存的二级缓存组合，当 Redis 缓存出现问题时，还可以从本地缓存中获取到部分数据。

**针对大量缓存同时失效的情况：**

1. **设置随机失效时间**（可选）：为缓存设置随机的失效时间，例如在固定过期时间的基础上加上一个随机值，这样可以避免大量缓存同时到期，从而减少缓存雪崩的风险。
2. **提前预热**（推荐）：针对热点数据提前预热，将其存入缓存中并设置合理的过期时间比如秒杀场景下的数据在秒杀结束之前不过期。
3. **持久缓存策略**（看情况）：虽然一般不推荐设置缓存永不过期，但对于某些关键性和变化不频繁的数据，可以考虑这种策略。

### 如何设计一个缓存策略，可以动态缓存热点数据呢？
热点数据动态缓存的策略总体思路：**通过数据最新访问时间来做排名，并过滤掉不常访问的数据，只留下经常访问的数据**。

**以电商平台场景中的例子，现在要求只缓存用户经常访问的 Top 1000 的商品：**

+ 先通过缓存系统做一个排序队列（比如存放 1000 个商品），系统会根据商品的访问时间，更新队列信息，越是最近访问的商品排名越靠前；
+ 同时系统会定期过滤掉队列中排名最后的 200 个商品，然后再从数据库中随机读取出 200 个商品加入队列中；
+ 这样当请求每次到达的时候，会先从队列中获取商品 ID，如果命中，就根据 ID 再从另一个缓存数据结构中读取实际的商品信息，并返回。

**在 Redis 中可以用 zadd 方法和 zrange 方法来完成排序队列和获取 200 个商品的操作。**

### 常见的缓存更新策略
#### Cache Aside Pattern（旁路缓存模式）
**Cache Aside Pattern 是我们平时使用比较多的一个缓存读写模式，比较适合读请求比较多的场景。**

Cache Aside Pattern 中服务端需要同时维系 db 和 cache，并且是以 db 的结果为准。

下面我们来看一下这个策略模式下的缓存读写步骤。

**写**：

+ 先更新 db
+ 然后直接删除 cache 。

![](https://cdn.nlark.com/yuque/0/2025/png/39185937/1736234928853-6997f3bd-7039-4e83-ae07-53351b86e10e.png)

**读** :

+ 从 cache 中读取数据，读取到就直接返回
+ cache 中读取不到的话，就从 db 中读取数据返回
+ 再把数据放到 cache 中。

![](https://cdn.nlark.com/yuque/0/2025/png/39185937/1736234928961-329a8bcc-3644-4143-8108-e7589de2fc8a.png)

现在我们再来分析一下 **Cache Aside Pattern 的缺陷**。

**缺陷 1：首次请求数据一定不在 cache 的问题**

解决办法：可以将热点数据可以提前放入 cache 中。

**缺陷 2：写操作比较频繁的话导致 cache 中的数据会被频繁被删除，这样会影响缓存命中率 **

解决办法：

+ 数据库和缓存数据强一致场景：更新 db 的时候同样更新 cache，不过我们需要加一个锁/分布式锁来保证更新 cache 的时候不存在线程安全问题。
+ 可以短暂地允许数据库和缓存数据不一致的场景：更新 db 的时候同样更新 cache，但是给缓存加一个比较短的过期时间，这样的话就可以保证即使数据不一致的话影响也比较小。

#### Read/Write Through Pattern（读写穿透）
Read/Write Through Pattern 中服务端把 cache 视为主要数据存储，从中读取数据并将数据写入其中。cache 服务负责将此数据读取和写入 db，从而减轻了应用程序的职责。

这种缓存读写策略小伙伴们应该也发现了在平时在开发过程中非常少见。抛去性能方面的影响，大概率是因为我们经常使用的分布式缓存 Redis 并没有提供 cache 将数据写入 db 的功能。

**写（Write Through）：**

+ 先查 cache，cache 中不存在，直接更新 db。
+ cache 中存在，则先更新 cache，然后 cache 服务自己更新 db（**同步更新 cache 和 db**）。

![](https://cdn.nlark.com/yuque/0/2025/png/39185937/1736235083769-bc559856-2169-474f-a228-2d8aca4d66b3.png)

**读(Read Through)：**

+ 从 cache 中读取数据，读取到就直接返回 。
+ 读取不到的话，先从 db 加载，写入到 cache 后返回响应。

![](https://cdn.nlark.com/yuque/0/2025/png/39185937/1736235083854-3d0ae184-e30a-412e-8e53-18ca52448590.png)

Read-Through Pattern 实际只是在 Cache-Aside Pattern 之上进行了封装。在 Cache-Aside Pattern 下，发生读请求的时候，如果 cache 中不存在对应的数据，是由客户端自己负责把数据写入 cache，而 Read Through Pattern 则是 cache 服务自己来写入缓存的，这对客户端是透明的。

和 Cache Aside Pattern 一样， Read-Through Pattern 也有首次请求数据一定不再 cache 的问题，对于热点数据可以提前放入缓存中

#### Write Behind Pattern（异步缓存写入）
Write Behind Pattern 和 Read/Write Through Pattern 很相似，两者都是由 cache 服务来负责 cache 和 db 的读写。

但是，两个又有很大的不同：**Read/Write Through 是同步更新 cache 和 db，而 Write Behind 则是只更新缓存，不直接更新 db，而是改为异步批量的方式来更新 db。**

很明显，这种方式对数据一致性带来了更大的挑战，比如 cache 数据可能还没异步更新 db 的话，cache 服务可能就就挂掉了。

这种策略在我们平时开发过程中也非常非常少见，但是不代表它的应用场景少，比如消息队列中消息的异步写入磁盘、MySQL 的 Innodb Buffer Pool 机制都用到了这种策略。

Write Behind Pattern 下 db 的写性能非常高，非常适合一些数据经常变化又对数据一致性要求没那么高的场景，比如浏览量、点赞量。

### 数据库和缓存如何保证一致性
采用旁路缓存模式，在更新数据库之后将删除缓存的操作放到消息队列当中，失败后会进行重试，重试次数过多报出异常

## Redis实战
### Redis如何实现延迟队列
在 Redis 可以使用有序集合（ZSet）的方式来实现延迟消息队列的，ZSet 有一个 Score 属性可以用来存储延迟执行的时间。

使用 zadd score1 value1 命令就可以一直往内存中生产消息。再利用zrangebysocre 查询符合条件的所有待处理的任务， 通过循环执行队列任务即可。

### ![](https://cdn.nlark.com/yuque/0/2025/png/39185937/1736235761165-8113b386-ea5d-40df-b4e8-4fec9a83d34e.png)
### <font style="color:#DF2A3F;">Redis的大key如何处理</font>
#### 什么是大key？
+ String 类型的 value 超过 1MB
+ 复合类型（List、Hash、Set、Sorted Set 等）的 value 包含的元素超过 5000 个（不过，对于复合类型的 value 来说，不一定包含的元素越多，占用的内存就越多）。

#### 大key会造成什么问题？
+ 客户端超时阻塞：由于 Redis 执行命令是单线程处理，然后在操作大 key 时会比较耗时，那么就会阻塞 Redis，从客户端这一视角看，就是很久很久都没有响应。
+ 网络阻塞：每次获取大 key 产生的网络流量较大，如果一个 key 的大小是 1 MB，每秒访问量为 1000，那么每秒会产生 1000MB 的流量，这对于普通千兆网卡的服务器来说是灾难性的。
+ 工作线程阻塞：如果使用 del 删除大 key 时，会阻塞工作线程，这样就没办法处理后续的命令。

#### [如何发现 bigkey？](https://javaguide.cn/database/redis/redis-questions-02.html#%E5%A6%82%E4%BD%95%E5%8F%91%E7%8E%B0-bigkey)
1、使用 Redis 自带的 `--bigkeys` 参数来查找。

2、使用 Redis 自带的 SCAN 命令

3、借助开源工具分析 RDB 文件。

4、借助公有云的 Redis 分析服务。

#### 如何处理 bigkey？
bigkey 的常见处理以及优化办法如下（这些方法可以配合起来使用）：

+ **分割 bigkey**：将一个 bigkey 分割为多个小 key。例如，将一个含有上万字段数量的 Hash 按照一定策略（比如二次哈希）拆分为多个 Hash。
+ **手动清理**：Redis 4.0+ 可以使用 `UNLINK` 命令来异步删除一个或多个指定的 key。Redis 4.0 以下可以考虑使用 `SCAN` 命令结合 `DEL` 命令来分批次删除。
+ **采用合适的数据结构**：例如，文件二进制数据不使用 String 保存、使用 HyperLogLog 统计页面 UV、Bitmap 保存状态信息（0/1）。
+ **开启 lazy-free（惰性删除/延迟释放）** ：lazy-free 特性是 Redis 4.0 开始引入的，指的是让 Redis 采用异步方式延迟释放 key 使用的内存，将该操作交给单独的子线程处理，避免阻塞主线程。

### Redis 管道有什么用？
**管道技术（Pipeline）**是客户端提供的一种批处理技术，用于一次处理多个 Redis 命令，从而提高整个交互的性能。

![](https://cdn.nlark.com/yuque/0/2025/png/39185937/1736236142200-ee595acb-3dbe-4cd8-94af-8aa48bbcd512.png)

使用**管道技术可以解决多个命令执行时的网络等待**，它是把多个命令整合到一起发送给服务器端处理之后统一返回给客户端，这样就免去了每条命令执行后都要等待的情况，从而有效地提高了程序的执行效率。

### <font style="color:#DF2A3F;">如何用Redis实现分布式锁</font>
Redis 本身可以被多个客户端共享访问，正好就是一个共享存储系统，可以用来保存分布式锁，而且 Redis 的读写性能高，可以应对高并发的锁操作场景。

Redis 的 SET 命令有个 NX 参数可以实现「key不存在才插入」，所以可以用它来实现分布式锁：

+ 如果 key 不存在，则显示插入成功，可以用来表示加锁成功；
+ 如果 key 存在，则会显示插入失败，可以用来表示加锁失败。

基于 Redis 节点实现分布式锁时，对于加锁操作，我们需要满足三个条件。

+ 加锁包括了读取锁变量、检查锁变量值和设置锁变量值三个操作，但需要以原子操作的方式完成，所以，我们使用 SET 命令带上 NX 选项来实现加锁；
+ 锁变量需要设置过期时间，以免客户端拿到锁后发生异常，导致锁一直无法释放，所以，我们在 SET 命令执行时加上 EX/PX 选项，设置其过期时间；
+ 锁变量的值需要能区分来自不同客户端的加锁操作，以免在释放锁时，出现误释放操作，所以，我们使用 SET 命令设置锁变量值时，每个客户端设置的值是一个唯一值，用于标识客户端；

满足这三个条件的分布式命令如下：

```c
SET lock_key unique_value NX PX 10000
```

+ lock_key 就是 key 键；
+ unique_value 是客户端生成的唯一的标识，区分来自不同客户端的锁操作；
+ NX 代表只在 lock_key 不存在时，才对 lock_key 进行设置操作；
+ PX 10000 表示设置 lock_key 的过期时间为 10s，这是为了避免客户端发生异常而无法释放锁。

而解锁的过程就是将 lock_key 键删除（del lock_key），但不能乱删，要保证执行操作的客户端就是加锁的客户端。所以，解锁的时候，我们要先判断锁的 unique_value 是否为加锁客户端，是的话，才将 lock_key 键删除。

可以看到，解锁是有两个操作，这时就需要 Lua 脚本来保证解锁的原子性，因为 Redis 在执行 Lua 脚本时，可以以原子性的方式执行，保证了锁释放操作的原子性。

```lua
// 释放锁时，先比较 unique_value 是否相等，避免锁的误释放
if redis.call("get",KEYS[1]) == ARGV[1] then
  return redis.call("del",KEYS[1])
else
  return 0
end
```

**基于 Redis 实现分布式锁的优点：**

1. **性能高效**
2. **实现方便**
3. **避免单点故障**

**缺点：**

1. **超时时间不好设置**
2. **Redis 主从复制模式中的数据是异步复制的，这样导致分布式锁的不可靠性**

# Redis数据类型
[小林coding-redis数据结构](https://xiaolincoding.com/redis/data_struct/data_struct.html#%E9%94%AE%E5%80%BC%E5%AF%B9%E6%95%B0%E6%8D%AE%E5%BA%93%E6%98%AF%E6%80%8E%E4%B9%88%E5%AE%9E%E7%8E%B0%E7%9A%84)

![](https://cdn.nlark.com/yuque/0/2025/png/39185937/1736847088379-c6ee3f39-4ce6-49d6-a667-cac79ae49d99.png)

# <font style="color:#DF2A3F;">主从复制</font>
## [第一次同步（小林coding链接）](https://xiaolincoding.com/redis/cluster/master_slave_replication.html#%E7%AC%AC%E4%B8%80%E6%AC%A1%E5%90%8C%E6%AD%A5)
主从服务器间的第一次同步的过程可分为三个阶段：

+ 第一阶段是建立链接、协商同步；（psync命令发送runId和offset，主服务器响应runId和主服务器的复制进度）
+ 第二阶段是主服务器同步数据给从服务器；（主服务器bgsave命令生成RDB快照，从服务器清空数据并载入主服务器的RDB快照）
+ 第三阶段是主服务器发送新写操作命令给从服务器。（将replication buffer 缓冲区所记录的这个过程中收到的新的写操作给发到从服务器）  
 

![](https://cdn.nlark.com/yuque/0/2025/png/39185937/1736858826203-4c8ffc08-8f26-4bf1-9d0a-ad920393ce98.png)

## 命令传播
![](https://cdn.nlark.com/yuque/0/2025/png/39185937/1736860243207-8ca878c0-c649-40f7-b256-75431010a3bb.png)

后续主服务器可以通过这个连接继续将写操作命令传播给从服务器，然后从服务器执行该命令，使得与主服务器的数据库状态相同。

而且这个连接是长连接的，目的是避免频繁的 TCP 连接和断开带来的性能开销。

上面的这个过程被称为**基于长连接的命令传播**，通过这种方式来保证第一次同步后的主从服务器的数据一致性。

## 增量复制（redis2.8之后）
![](https://cdn.nlark.com/yuque/0/2025/png/39185937/1736860531943-77e524de-6069-4bb7-994c-4f3799e755ad.png)

主要有三个步骤：

+ 从服务器在恢复网络后，会发送 psync 命令给主服务器，此时的 psync 命令里的 offset 参数不是 -1；
+ 主服务器收到该命令后，然后用 CONTINUE 响应命令告诉从服务器接下来采用增量复制的方式同步数据；
+ 然后主服务将主从服务器断线期间，所执行的写命令发送给从服务器，然后从服务器执行这些命令。

### repl_backlog_buffer（环形缓冲区）
在主服务器进行命令传播时，不仅会将写命令发送给从服务器，还会将写命令写入到 repl_backlog_buffer 缓冲区里，因此这个缓冲区里会保存着最近传播的写命令。

主服务器根据自己的写偏移量和从服务器的读偏移量来判断执行哪种同步：

+ 如果判断出从服务器要读取的数据还在 repl_backlog_buffer 缓冲区里，那么主服务器将采用**增量同步**的方式；
+ 相反，如果判断出从服务器要读取的数据已经不存在 repl_backlog_buffer 缓冲区里，那么主服务器将采用**全量同步**的方式。

## 哨兵（Redis2.8之后）
实现**主从节点故障转移**。它会监测主节点是否存活，如果发现主节点挂了，它就会选举一个从节点切换为主节点，并且把新主节点的相关信息通知给从节点和客户端。

哨兵节点主要负责三件事情：**监控、选主、通知**。

![](https://cdn.nlark.com/yuque/0/2025/png/39185937/1736865478337-cb46d0ef-c2d2-4ee2-abb5-06ecce3e3de6.png)

## 主观下线
哨兵会每隔 1 秒给所有主从节点发送 PING 命令，当主从节点收到 PING 命令后，会发送一个响应命令给哨兵，这样就可以判断它们是否在正常运行。如果主节点或者从节点没有在规定的时间内响应哨兵的 PING 命令，哨兵就会将它们标记为「**主观下线**」。

哨兵在部署的时候不会只部署一个节点，而是用多个节点部署成**哨兵集群**（_最少需要三台机器来部署哨兵集群_），**通过多个哨兵节点一起判断，就可以就可以避免单个哨兵因为自身网络状况不好，而误判主节点下线的情况**。同时，多个哨兵的网络同时不稳定的概率较小，由它们一起做决策，误判率也能降低。

**主观下线**代表当前哨兵认为某个节点下线了

## 客观下线
当一个哨兵判断主节点为「主观下线」后，就会向其他哨兵发起命令，其他哨兵收到这个命令后，就会根据自身和主节点的网络状况，做出赞成投票或者拒绝投票的响应。

![](https://cdn.nlark.com/yuque/0/2025/png/39185937/1736865788442-bcf8f1c2-214e-4529-9a80-51e28ffb1d5d.png)

当这个哨兵的赞同票数达到哨兵配置文件中的 quorum 配置项设定的值后，这时主节点就会被该哨兵标记为「客观下线」。（quorum 的值一般设置为哨兵个数的二分之一加 1，例如 3 个哨兵就设置 2。）

## 候选者如何选举成为 Leader？
哪个哨兵节点判断主节点为「客观下线」，这个哨兵节点就是候选者。

候选者会向其他哨兵发送命令，表明希望成为 Leader 来执行主从切换，让所有其他哨兵对它进行投票。

那么在投票过程中，任何一个「候选者」，要满足两个条件：

+ 第一，拿到半数以上的赞成票；
+ 第二，拿到的票数同时还需要大于等于哨兵配置文件中的 quorum 值。

## 主从故障转移的过程是怎样的
![](https://cdn.nlark.com/yuque/0/2025/png/39185937/1736997449425-5e76bbf9-035c-417b-8a0e-5f417e297ef6.png)

主从故障转移操作包含以下四个步骤：

+ 第一步：在已下线主节点（旧主节点）属下的所有「从节点」里面，挑选出一个从节点，并将其转换为主节点。
+ 第二步：让已下线主节点属下的所有「从节点」修改复制目标，修改为复制「新主节点」；
+ 第三步：将新主节点的 IP 地址和信息，通过「发布者/订阅者机制」通知给客户端；
+ 第四步：继续监视旧主节点，当这个旧主节点重新上线时，将它设置为新主节点的从节点；

### 步骤一：选出新主节点
+ 第一轮考察：哨兵首先会根据从节点的优先级来进行排序，优先级越小排名越靠前。
+ 第二轮考察：如果优先级相同，则查看复制的下标，哪个从「主节点」接收的复制数据多，哪个就靠前。
+ 第三轮考察：如果优先级和下标都相同，就选择从节点 ID 较小的那个

![](https://cdn.nlark.com/yuque/0/2025/webp/39185937/1736997795603-47a2150c-904f-4c9c-b14c-6170a32894bf.webp)  
 

