## 硬件结构
### 冯诺依曼模型
运算器、控制器、存储器、输入设备、输出设备

## 操作系统结构
## 内存管理
### 为什么要有虚拟内存
**虚拟内存(Virtual Memory)** 是计算机系统内存管理非常重要的一个技术，本质上来说它只是逻辑存在的，是一个假想出来的内存空间，主要作用是作为进程访问主存（物理内存）的桥梁并简化内存管理。

![](https://cdn.nlark.com/yuque/0/2024/png/39185937/1735635953084-b508326e-68a3-4ab4-be50-8a6ca31baa4e.png)

总结来说，虚拟内存主要提供了下面这些能力：

+ **隔离进程**：物理内存通过虚拟地址空间访问，虚拟地址空间与进程一一对应。每个进程都认为自己拥有了整个物理内存，进程之间彼此隔离，一个进程中的代码无法更改正在由另一进程或操作系统使用的物理内存。
+ **提升物理内存利用率**：有了虚拟地址空间后，操作系统只需要将进程当前正在使用的部分数据或指令加载入物理内存。
+ **简化内存管理**：进程都有一个一致且私有的虚拟地址空间，程序员不用和真正的物理内存打交道，而是借助虚拟地址空间访问物理内存，从而简化了内存管理。
+ **多个进程共享物理内存**：进程在运行过程中，会加载许多操作系统的动态库。这些库对于每个进程而言都是公用的，它们在内存中实际只会加载一份，这部分称为共享内存。
+ **提高内存使用安全性**：控制进程对物理内存的访问，隔离不同进程的访问权限，提高系统的安全性。
+ **提供更大的可使用内存空间**：可以让程序拥有超过系统物理内存大小的可用内存空间。这是因为当物理内存不够用时，可以利用磁盘充当，将物理内存页（通常大小为 4 KB）保存到磁盘文件（会影响读写速度），数据或代码页会根据需要在物理内存与磁盘之间移动。

### 分段机制
**分段机制（Segmentation）** 以段(一段 **连续** 的物理内存)的形式管理/分配物理内存。应用程序的虚拟地址空间被分为大小不等的段，段是有实际意义的，每个段定义了一组逻辑信息，例如有主程序段 MAIN、子程序段 X、数据段 D 及栈段 S 等。

段号+段内偏移量  内存外部碎片



### <font style="color:rgb(60, 60, 67);">分页机制</font>
**<font style="color:rgb(60, 60, 67);">分页机制（Paging）</font>**<font style="color:rgb(60, 60, 67);"> 把主存（物理内存）分为连续等长的物理页，应用程序的虚拟地址空间划也被分为连续等长的虚拟页。现代操作系统广泛采用分页机制。</font>

页号+页内偏移量 内存内部碎片

**快表（TLB）：**

使用 TLB 之后的地址翻译流程是这样的：

1. 用虚拟地址中的虚拟页号作为 key 去 TLB 中查询；
2. 如果能查到对应的物理页的话，就不用再查询页表了，这种情况称为 TLB 命中（TLB hit)。
3. 如果不能查到对应的物理页的话，还是需要去查询主存中的页表，同时将页表中的该映射表项添加到 TLB 中，这种情况称为 TLB 未命中（TLB miss)。
4. 当 TLB 填满后，又要登记新页时，就按照一定的淘汰策略淘汰掉快表中的一个页。

### 分页机制和分段机制有哪些共同点和区别？
**共同点**：

+ 都是非连续内存管理的方式。
+ 都采用了地址映射的方法，将虚拟地址映射到物理地址，以实现对内存的管理和保护。

**区别**：

+ 分页机制以页面为单位进行内存管理，而分段机制以段为单位进行内存管理。页的大小是固定的，由操作系统决定，通常为 2 的幂次方。而段的大小不固定，取决于我们当前运行的程序。
+ 页是物理单位，即操作系统将物理内存划分成固定大小的页面，每个页面的大小通常是 2 的幂次方，例如 4KB、8KB 等等。而段则是逻辑单位，是为了满足程序对内存空间的逻辑需求而设计的，通常根据程序中数据和代码的逻辑结构来划分。
+ 分段机制容易出现外部内存碎片，即在段与段之间留下碎片空间(不足以映射给虚拟地址空间中的段)。分页机制解决了外部内存碎片的问题，但仍然可能会出现内部内存碎片。
+ 分页机制采用了页表来完成虚拟地址到物理地址的映射，页表通过一级页表和二级页表来实现多级映射；而分段机制则采用了段表来完成虚拟地址到物理地址的映射，每个段表项中记录了该段的起始地址和长度信息。
+ 分页机制对程序没有任何要求，程序只需要按照虚拟地址进行访问即可；而分段机制需要程序员将程序分为多个段，并且显式地使用段寄存器来访问不同的段。

### <font style="color:rgb(60, 60, 67);">段页机制</font>
<font style="color:rgb(60, 60, 67);">结合了段式管理和页式管理的一种内存管理机制，把物理内存先分成若干段，每个段又继续分成若干大小相等的页。</font>

<font style="color:rgb(60, 60, 67);">在段页式机制下，地址翻译的过程分为两个步骤：</font>

1. <font style="color:rgb(60, 60, 67);">段式地址映射。</font>
2. <font style="color:rgb(60, 60, 67);">页式地址映射。</font>

###  内存满了之后会有什么处理  
#### 1. 使用交换空间 (Swap)
+ **概念**: 如果物理内存耗尽，操作系统会将部分内存数据写入磁盘上的交换分区或交换文件，以释放内存。
+ **优缺点**:
    - **优点**: 提供了额外的虚拟内存，防止程序因内存不足崩溃。
    - **缺点**: 交换空间速度远慢于物理内存，可能导致系统性能显著下降（俗称“变卡”或“换页风暴”）。

#### 2. 触发内存回收 (Memory Reclamation)
+ **机制**: 操作系统会尝试回收不活跃的内存，比如清理缓存或释放未使用的页面。
+ **优缺点**:
    - **优点**: 可以迅速释放部分内存。
    - **缺点**: 回收可能会影响部分正在运行的低优先级进程的性能。

#### 3. 触发 OOM Killer（Out-Of-Memory Killer）
+ **概念**: 在 Linux 等系统中，如果内存和交换空间都耗尽，内核会启动 OOM Killer 机制，强制终止某些进程。
+ **选择目标进程**:
    - 通常会选择内存占用较大的进程。
    - 使用特定策略（如 `oom_score`）判断哪个进程“优先被杀”。
+ **后果**:
    - 某些进程可能被强制关闭，导致数据丢失或服务中断。

### 如何避免预读失败和缓存污染的问题
## 进程管理
### 进程：程序的一次运行
#### [进程的控制结构](https://xiaolincoding.com/os/4_process/process_base.html#%E8%BF%9B%E7%A8%8B%E7%9A%84%E6%8E%A7%E5%88%B6%E7%BB%93%E6%9E%84)
#### [进程的控制](https://xiaolincoding.com/os/4_process/process_base.html#%E8%BF%9B%E7%A8%8B%E7%9A%84%E6%8E%A7%E5%88%B6)
#### [进程的上下文切换](https://xiaolincoding.com/os/4_process/process_base.html#%E8%BF%9B%E7%A8%8B%E7%9A%84%E4%B8%8A%E4%B8%8B%E6%96%87%E5%88%87%E6%8D%A2)
### 线程：进程当中的一条执行流程，共用进程的堆和方法区并且有私有的程序计数器、虚拟机栈和本地方法栈
### 进程之间的通信方式
1. **管道/匿名管道(Pipes)** ：用于具有亲缘关系的父子进程间或者兄弟进程之间的通信。
2. **有名管道(Named Pipes)** : 匿名管道由于没有名字，只能用于亲缘关系的进程间通信。为了克服这个缺点，提出了有名管道。有名管道严格遵循 **先进先出(First In First Out)** 。有名管道以磁盘文件的方式存在，可以实现本机任意两个进程通信。
3. **信号(Signal)** ：信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生；
4. **消息队列(Message Queuing)** ：消息队列是消息的链表,具有特定的格式,存放在内存中并由消息队列标识符标识。管道和消息队列的通信数据都是先进先出的原则。与管道（无名管道：只存在于内存中的文件；命名管道：存在于实际的磁盘介质或者文件系统）不同的是消息队列存放在内核中，只有在内核重启(即，操作系统重启)或者显式地删除一个消息队列时，该消息队列才会被真正的删除。消息队列可以实现消息的随机查询,消息不一定要以先进先出的次序读取,也可以按消息的类型读取.比 FIFO 更有优势。消息队列克服了信号承载信息量少，管道只能承载无格式字 节流以及缓冲区大小受限等缺点。
5. **信号量(Semaphores)** ：信号量是一个计数器，用于多进程对共享数据的访问，信号量的意图在于进程间同步。这种通信方式主要用于解决与同步相关的问题并避免竞争条件。
6. **共享内存(Shared memory)** ：使得多个进程可以访问同一块内存空间，不同进程可以及时看到对方进程中对共享内存中数据的更新。这种方式需要依靠某种同步操作，如互斥锁和信号量等。可以说这是最有用的进程间通信方式。
7. **套接字(Sockets)** : 此方法主要用于在客户端和服务器之间通过网络进行通信。套接字是支持 TCP/IP 的网络通信的基本操作单元，可以看做是不同主机之间的进程进行双向通信的端点，简单的说就是通信的两方的一种约定，用套接字中的相关函数来完成通信过程。

### 线程之间的同步方式
1. **互斥锁(Mutex)** ：采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。因为互斥对象只有一个，所以可以保证公共资源不会被多个线程同时访问。比如 Java 中的 `synchronized` 关键词和各种 `Lock` 都是这种机制。
2. **读写锁（Read-Write Lock）** ：允许多个线程同时读取共享资源，但只有一个线程可以对共享资源进行写操作。
3. **信号量(Semaphore)** ：它允许同一时刻多个线程访问同一资源，但是需要控制同一时刻访问此资源的最大线程数量。
4. **屏障（Barrier）** ：屏障是一种同步原语，用于等待多个线程到达某个点再一起继续执行。当一个线程到达屏障时，它会停止执行并等待其他线程到达屏障，直到所有线程都到达屏障后，它们才会一起继续执行。比如 Java 中的 `CyclicBarrier` 是这种机制。
5. **事件(Event)** :Wait/Notify：通过通知操作的方式来保持多线程同步，还可以方便的实现多线程优先级的比较操作。

### 死锁的必要条件
1. **互斥**：资源必须处于非共享模式，即一次只有一个进程可以使用。如果另一进程申请该资源，那么必须等待直到该资源被释放为止。
2. **占有并等待**：一个进程至少应该占有一个资源，并等待另一资源，而该资源被其他进程所占有。
3. **非抢占**：资源不能被抢占。只能在持有资源的进程完成任务后，该资源才会被释放。
4. **循环等待**：有一组等待进程 `{P0, P1,..., Pn}`， `P0` 等待的资源被 `P1` 占有，`P1` 等待的资源被 `P2` 占有，……，`Pn-1` 等待的资源被 `Pn` 占有，`Pn` 等待的资源被 `P0` 占有。

### 死锁预防：破坏2、3、4条件
### 死锁避免：银行家算法
### <font style="color:rgb(60, 60, 67);">能写一个模拟产生死锁的代码吗？</font>
```java
public class DeadLockDemo {
    private static Object resource1 = new Object();
    private static Object resource2 = new Object();

    public static void main(String[] args) {
        new Thread(() -> {
            synchronized (resource1){
                System.out.println(Thread.currentThread().getName() + "获取资源1");
                try{
                    // 模拟线程运行
                    Thread.sleep(1000);
                }catch(InterruptedException e){
                    e.printStackTrace();
                }
                System.out.println(Thread.currentThread().getName() +"等待获取资源2");
                synchronized (resource2){
                    System.out.println(Thread.currentThread().getName() + "获取资源2");
                }
            }
        }, "thread1").start();
        new Thread(() -> {
            synchronized (resource2){
                System.out.println(Thread.currentThread().getName() + "获取资源2");
                try{
                    // 模拟线程运行
                    Thread.sleep(1000);
                }catch(InterruptedException e){
                    e.printStackTrace();
                }
                System.out.println(Thread.currentThread().getName() +"等待获取资源1");
                synchronized (resource1){
                    System.out.println(Thread.currentThread().getName() + "获取资源1");
                }
            }
        }, "thread2").start();
    }
}

```

### 互斥锁与自旋锁
+ **互斥锁**加锁失败后，线程会**释放CPU**，给其他线程
+ **自旋锁**加锁失败后，线程会**忙等待**，直到它拿到锁

### 读写锁
### 悲观锁和乐观锁
+ **悲观锁：**假定每次对共享资源的访问都会发生冲突，所以需要先上锁
+ **乐观锁：**假定每次访问都没有冲突，先修改共享资源，再验证这段时间有没有发生冲突，如果发现资源已经被修改过则放弃本次操作

### 线程崩溃进程一定会崩溃吗
+ 一般来说如果是因为线程非法访问内存引起的崩溃，那么进程一定会崩溃，**因为各个进程的地址空间是共享的**
+ 线程崩溃不会导致JVM进程崩溃，因为JVM自定义了自己的信号处理函数，拦截了终止进程的信号

## 调度算法
### 进程调度算法
1. **先来先服务**
2. **短作业优先**
3. **高响应比优先**
4. **优先级优先**
5. **多级反馈优先队列**
6. **时间片轮转**

### 内存页面置换算法
1. 最佳页面置换算法（实现不了）
2. 先进先出
3. 最近最久未使用
4. 最少使用
5. 时钟页面

### 磁盘调度算法
先来先服务

最短寻道时间优先

扫描算法

循环扫描

LOOK和C-LOOK算法

## [文件系统](https://xiaolincoding.com/os/6_file_system/file_system.html#%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%9F%BA%E6%9C%AC%E7%BB%84%E6%88%90)(基本没问过就不整理了)
阻塞型IO、非阻塞型IO、IO多路复用、同步IO、异步IO、

## 网络系统
### 什么是零拷贝技术
#### 为什么需要DMA（直接内存访问）
代替CPU做数据搬运，解决CPU花大量时间在数据搬运上而不能处理其他事情的问题

#### 传统的文件传输：
read（）调用：用户态->内核态（CPU发起IO请求让DMA读取数据1）->用户态（DMA搬运数据完成后CPU将数据copy到用户空间）

write（）调用：用户态->内核态（CPU将用户空间的数据copy到内核空间的socket缓冲区，DMA将数据搬运到网卡的缓冲区）->用户态（指令完成返回）

#### mmap+write
直接将内核缓冲区的数据映射到用户空间无需copy，这样可以直接在内核空间进行传输，减少一次copy，但仍需四次上下文切换

#### sendfile
无需write，sendfile命令直接完成read和write两个步骤，传输数据也只需要在内核空间，就是只需要一次系统调用两次上下文切换，三次copy就可以完成

如果网卡支SG-DMA技术，甚至不用内核空间传输，可以通过DMA从文件中读取数据之后直接传输到网卡的缓冲区（真正的零拷贝，无需CPU参与）

### PageCache（磁盘高速缓存）
+ 缓存最近被访问的数据
+ 预读功能

但是传输大文件（GB级别的文件时），PageCache会不起作用甚至降低效率，因为文件太大会很快将PageCache中的空间占满，局部性原理就会不起作用，白白浪费一次DMA拷贝的性能

### 传输大文件使用异步IO+直接IO（绕过PageCache）
### IO多路复用
#### select/poll
将已连接的Socket都放入到一个文件描述符集合

**两次遍历：**内核态遍历检查是否有事件发生并标记，用户态遍历查找发生事件的socket并处理

**两次copy：**用户到内核，内核到用户

select方法使用固定长度的**BitsMap**表示文件描述符集合，最大长度为**1024**

poll方法用**动态数组**，以链表形式组织，受**系统的最大文件描述符**个数影响

#### epoll
+ 在内核中用红黑树来跟踪所有待检测的文件描述符，用户每次只需要将需要监听的socket传入内核即可，而不用每次都拷贝所有的文件描述符集合
+ 使用事件驱动的机制，维护一个链表来记录就绪事件，当用户调用epoll_wait函数时只会返回有事件发生的文件描述符个数

